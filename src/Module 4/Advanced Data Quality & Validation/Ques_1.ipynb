{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Drift Impact on Model\n",
    "# Question: Use a simple linear regression model to demonstrate how data drift affects model predictions.\n",
    "\n",
    "# 1. Train a model on the original data:\n",
    "# 2. Evaluate on the drifted data:\n",
    "# 3. Compare errors:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitoring Data Distribution Changes\n",
    "# Question: Use Python to monitor distribution changes in features to detect potential data drift.\n",
    "\n",
    "# 1. Calculate feature statistics (mean and standard deviation) for both original and drifted data:\n",
    "# 2. Compare statistics:\n",
    "# 3. Set thresholds to detect significant drift:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automating Data Quality Checks with Python\n",
    "# Question: Automate a basic data validation process using Python to ensure the dataset's\n",
    "# structural integrity.\n",
    "\n",
    "# 1. Define validation checks:\n",
    "# 2. Apply validation:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introducing Great Expectations for Data Validation\n",
    "# Question: Use Great Expectations to set up data validation checks for a dataset.\n",
    "\n",
    "# 1. Install Great Expectations:\n",
    "# 2. Create a new expectations suite:\n",
    "# 3. Load data and generate expectations:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automating Constraint Checks with Python\n",
    "# Question: Automate primary key and foreign key constraint checks using Python to ensure dataset compliance.\n",
    "\n",
    "\n",
    "# 1. Assuming datasets exist with primary and foreign key relationships in pandas dataframes employees_df and departments_df :\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Data Drift Detection using Statistical Tests\n",
    "# Question: Implement Kolmogorov-Smirnov test using Python to detect data drift at a more sophisticated level.\n",
    "\n",
    "# 1. Use SciPy to perform KS test:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Drift Impact on Model ---\n",
      "Mean Squared Error on drifted data: 1.0812\n",
      "Mean Squared Error on original data: 0.3052\n",
      "Observation: The error is likely higher on the drifted data, demonstrating the impact of data distribution changes on model performance.\n",
      "\n",
      "--- Monitoring Data Distribution Changes ---\n",
      "Original data - Mean: 0.4706, Standard Deviation: 0.3158\n",
      "Drifted data - Mean: 0.9739, Standard Deviation: 0.2845\n",
      "Difference in means: 0.5034\n",
      "Difference in standard deviations: 0.0313\n",
      "Potential data drift detected based on mean difference (>0.2).\n",
      "No significant drift detected based on standard deviation difference (>0.1).\n",
      "\n",
      "--- Automating Data Quality Checks with Python ---\n",
      "Running data quality checks:\n",
      "Validation failed: Column 'value' has missing values.\n",
      "\n",
      "--- Introducing Great Expectations for Data Validation ---\n",
      "Assuming Great Expectations is already installed (`pip install great_expectations`).\n",
      "To create a new expectations suite, you would typically run:\n",
      "`great_expectations init` and then `great_expectations suite new` in your terminal.\n",
      "This interactive process helps you define your data source and create a suite.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EphemeralDataContext' object has no attribute 'add_pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 122\u001b[0m\n\u001b[1;32m    119\u001b[0m expectation_suite_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_expectation_suite\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datasource_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m context\u001b[38;5;241m.\u001b[39mlist_datasources():\n\u001b[0;32m--> 122\u001b[0m     \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_pandas\u001b[49m(name\u001b[38;5;241m=\u001b[39mdatasource_name, batch_kwargs_generators\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    124\u001b[0m batch_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: data_quality}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expectation_suite_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m context\u001b[38;5;241m.\u001b[39mlist_expectation_suite_names():\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EphemeralDataContext' object has no attribute 'add_pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import kstest\n",
    "import great_expectations as ge\n",
    "\n",
    "# --- Data Drift Impact on Model ---\n",
    "print(\"\\n--- Data Drift Impact on Model ---\")\n",
    "\n",
    "# 1. Train a model on the original data:\n",
    "original_data = pd.DataFrame({'feature': np.random.rand(100), 'target': 2 * np.random.rand(100) + np.random.normal(0, 0.1, 100)})\n",
    "X_original = original_data[['feature']]\n",
    "y_original = original_data['target']\n",
    "model = LinearRegression()\n",
    "model.fit(X_original, y_original)\n",
    "\n",
    "# 2. Evaluate on the drifted data:\n",
    "drifted_data = pd.DataFrame({'feature': np.random.rand(100) + 0.5, 'target': 2 * (np.random.rand(100) + 0.5) + np.random.normal(0, 0.2, 100)})\n",
    "X_drifted = drifted_data[['feature']]\n",
    "y_drifted = drifted_data['target']\n",
    "predictions_drifted = model.predict(X_drifted)\n",
    "mse_drifted = mean_squared_error(y_drifted, predictions_drifted)\n",
    "print(f\"Mean Squared Error on drifted data: {mse_drifted:.4f}\")\n",
    "\n",
    "# 3. Evaluate on the original data for comparison:\n",
    "predictions_original = model.predict(X_original)\n",
    "mse_original = mean_squared_error(y_original, predictions_original)\n",
    "print(f\"Mean Squared Error on original data: {mse_original:.4f}\")\n",
    "\n",
    "print(\"Observation: The error is likely higher on the drifted data, demonstrating the impact of data distribution changes on model performance.\")\n",
    "\n",
    "# --- Monitoring Data Distribution Changes ---\n",
    "print(\"\\n--- Monitoring Data Distribution Changes ---\")\n",
    "\n",
    "# 1. Calculate feature statistics (mean and standard deviation) for both original and drifted data:\n",
    "original_mean = original_data['feature'].mean()\n",
    "original_std = original_data['feature'].std()\n",
    "drifted_mean = drifted_data['feature'].mean()\n",
    "drifted_std = drifted_data['feature'].std()\n",
    "\n",
    "print(f\"Original data - Mean: {original_mean:.4f}, Standard Deviation: {original_std:.4f}\")\n",
    "print(f\"Drifted data - Mean: {drifted_mean:.4f}, Standard Deviation: {drifted_std:.4f}\")\n",
    "\n",
    "# 2. Compare statistics:\n",
    "mean_diff = abs(original_mean - drifted_mean)\n",
    "std_diff = abs(original_std - drifted_std)\n",
    "print(f\"Difference in means: {mean_diff:.4f}\")\n",
    "print(f\"Difference in standard deviations: {std_diff:.4f}\")\n",
    "\n",
    "# 3. Set thresholds to detect significant drift:\n",
    "mean_threshold = 0.2\n",
    "std_threshold = 0.1\n",
    "\n",
    "if mean_diff > mean_threshold:\n",
    "    print(f\"Potential data drift detected based on mean difference (>{mean_threshold}).\")\n",
    "else:\n",
    "    print(f\"No significant drift detected based on mean difference (>{mean_threshold}).\")\n",
    "\n",
    "if std_diff > std_threshold:\n",
    "    print(f\"Potential data drift detected based on standard deviation difference (>{std_threshold}).\")\n",
    "else:\n",
    "    print(f\"No significant drift detected based on standard deviation difference (>{std_threshold}).\")\n",
    "\n",
    "# --- Automating Data Quality Checks with Python ---\n",
    "print(\"\\n--- Automating Data Quality Checks with Python ---\")\n",
    "\n",
    "# Sample data\n",
    "data_quality = pd.DataFrame({'ID': [1, 2, 3, 4, 5],\n",
    "                            'value': [10, 20, None, 40, 50],\n",
    "                            'category': ['A', 'B', 'A', 'C', 'B']})\n",
    "\n",
    "# 1. Define validation checks:\n",
    "def check_missing_values(df, column):\n",
    "    if df[column].isnull().sum() > 0:\n",
    "        print(f\"Validation failed: Column '{column}' has missing values.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_data_type(df, column, expected_type):\n",
    "    if df[column].dtype != expected_type:\n",
    "        print(f\"Validation failed: Column '{column}' has incorrect data type (expected {expected_type}, got {df[column].dtype}).\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_categorical_values(df, column, allowed_values):\n",
    "    invalid_values = df[column][~df[column].isin(allowed_values)].unique()\n",
    "    if len(invalid_values) > 0:\n",
    "        print(f\"Validation failed: Column '{column}' has invalid values: {invalid_values}.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# 2. Apply validation:\n",
    "print(\"Running data quality checks:\")\n",
    "is_valid = True\n",
    "is_valid &= check_missing_values(data_quality, 'value')\n",
    "is_valid &= check_data_type(data_quality, 'ID', 'int64')\n",
    "is_valid &= check_categorical_values(data_quality, 'category', ['A', 'B', 'C'])\n",
    "\n",
    "if is_valid:\n",
    "    print(\"Data quality checks passed.\")\n",
    "\n",
    "# --- Introducing Great Expectations for Data Validation ---\n",
    "print(\"\\n--- Introducing Great Expectations for Data Validation ---\")\n",
    "\n",
    "# 1. Install Great Expectations:\n",
    "print(\"Assuming Great Expectations is already installed (`pip install great_expectations`).\")\n",
    "\n",
    "# 2. Create a new expectations suite:\n",
    "print(\"To create a new expectations suite, you would typically run:\")\n",
    "print(\"`great_expectations init` and then `great_expectations suite new` in your terminal.\")\n",
    "print(\"This interactive process helps you define your data source and create a suite.\")\n",
    "\n",
    "# For demonstration purposes, let's simulate loading data and adding an expectation programmatically:\n",
    "context = ge.get_context()\n",
    "datasource_name = \"my_pandas_datasource\"\n",
    "data_asset_name = \"my_data_asset\"\n",
    "expectation_suite_name = \"my_expectation_suite\"\n",
    "\n",
    "if datasource_name not in context.list_datasources():\n",
    "    context.add_pandas(name=datasource_name, batch_kwargs_generators=None)\n",
    "\n",
    "batch_kwargs = {\"dataset\": data_quality}\n",
    "\n",
    "if expectation_suite_name not in context.list_expectation_suite_names():\n",
    "    suite = context.create_expectation_suite(expectation_suite_name=expectation_suite_name)\n",
    "    validator = context.get_validator(batch_kwargs=batch_kwargs, expectation_suite_name=expectation_suite_name, datasource_name=datasource_name, data_asset_name=data_asset_name)\n",
    "    validator.expect_column_to_not_have_missing_values(\"value\")\n",
    "    validator.expect_column_values_to_be_in_set(\"category\", [\"A\", \"B\", \"C\"])\n",
    "    validator.save_expectation_suite()\n",
    "    print(f\"Expectation suite '{expectation_suite_name}' created and saved.\")\n",
    "else:\n",
    "    print(f\"Expectation suite '{expectation_suite_name}' already exists.\")\n",
    "    validator = context.get_validator(batch_kwargs=batch_kwargs, expectation_suite_name=expectation_suite_name, datasource_name=datasource_name, data_asset_name=data_asset_name)\n",
    "\n",
    "# 3. Load data and generate expectations:\n",
    "print(\"\\nRunning expectations:\")\n",
    "validation_result = validator.validate()\n",
    "print(validation_result)\n",
    "if not validation_result[\"success\"]:\n",
    "    print(\"Great Expectations found issues with the data.\")\n",
    "else:\n",
    "    print(\"Great Expectations validation passed.\")\n",
    "\n",
    "# --- Automating Constraint Checks with Python ---\n",
    "print(\"\\n--- Automating Constraint Checks with Python ---\")\n",
    "\n",
    "# 1. Assuming datasets exist with primary and foreign key relationships in pandas dataframes employees_df and departments_df :\n",
    "employees_data = {'employee_id': [101, 102, 103, 104, 105],\n",
    "                  'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "                  'department_id': [1, 2, 1, 3, 2]}\n",
    "employees_df = pd.DataFrame(employees_data)\n",
    "\n",
    "departments_data = {'department_id': [1, 2, 3],\n",
    "                    'department_name': ['HR', 'Engineering', 'Sales']}\n",
    "departments_df = pd.DataFrame(departments_data)\n",
    "\n",
    "# Define primary key and foreign key columns\n",
    "employee_pk_col = 'employee_id'\n",
    "department_pk_col = 'department_id'\n",
    "employee_fk_col = 'department_id'\n",
    "\n",
    "# 2. Apply constraint checks:\n",
    "\n",
    "def check_primary_key_uniqueness(df, pk_col):\n",
    "    if df[pk_col].duplicated().any():\n",
    "        print(f\"Constraint check failed: Primary key column '{pk_col}' has duplicate values.\")\n",
    "        return False\n",
    "    print(f\"Constraint check passed: Primary key column '{pk_col}' is unique.\")\n",
    "    return True\n",
    "\n",
    "def check_foreign_key_references(fk_df, fk_col, pk_df, pk_col):\n",
    "    invalid_fk_values = fk_df[fk_col][~fk_df[fk_col].isin(pk_df[pk_col])].unique()\n",
    "    if len(invalid_fk_values) > 0:\n",
    "        print(f\"Constraint check failed: Foreign key column '{fk_col}' has values that do not exist in primary key column '{pk_col}': {invalid_fk_values}.\")\n",
    "        return False\n",
    "    print(f\"Constraint check passed: Foreign key column '{fk_col}' references valid values in primary key column '{pk_col}'.\")\n",
    "    return True\n",
    "\n",
    "print(\"Running constraint checks:\")\n",
    "check_primary_key_uniqueness(employees_df, employee_pk_col)\n",
    "check_primary_key_uniqueness(departments_df, department_pk_col)\n",
    "check_foreign_key_references(employees_df, employee_fk_col, departments_df, department_pk_col)\n",
    "\n",
    "# --- Advanced Data Drift Detection using Statistical Tests ---\n",
    "print(\"\\n--- Advanced Data Drift Detection using Statistical Tests ---\")\n",
    "\n",
    "# 1. Use SciPy to perform KS test:\n",
    "original_feature = original_data['feature'].values\n",
    "drifted_feature = drifted_data['feature'].values\n",
    "\n",
    "ks_statistic, p_value = kstest(original_feature, drifted_feature)\n",
    "\n",
    "print(f\"Kolmogorov-Smirnov Statistic: {ks_statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(f\"Reject null hypothesis. Significant data drift detected (p < {alpha}).\")\n",
    "else:\n",
    "    print(f\"Fail to reject null hypothesis. No significant data drift detected (p >= {alpha}).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
