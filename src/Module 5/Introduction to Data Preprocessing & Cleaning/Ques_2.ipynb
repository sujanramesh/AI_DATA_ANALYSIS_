{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance of Data Cleaning\n",
    "\n",
    "# 1. Missing Values: Missing data points in a dataset can lead to biased results.\n",
    "#     Task 1: Load a dataset and identify which columns have missing values.\n",
    "#     Task 2: Replace missing values in a dataset with the column mean or mode.\n",
    "#     Task 3: Compare model performance with and without handling missing values.\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Duplicate Data: Repeated data points can skew analysis and model results.\n",
    "#     Task 1: Identify and remove duplicate entries from a dataset using a programming language or tool.\n",
    "#     Task 2: Document the before-and-after dataset shape to understand the impact of duplicates.\n",
    "#     Task 3: Explain to a classmate how duplicate data can affect prediction accuracy.\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Incorrect Data Types: Data stored in incorrect formats can lead to parsing errors or incorrect analysis.\n",
    "#     Task 1: Convert a column of string numbers to integers in a dataset.\n",
    "#     Task 2: Identify and correct columns with inconsistent data types in a dataset.\n",
    "#     Task 3: Discuss why correct data types are critical for feature engineering.\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Outliers & Inconsistencies: Irregularities in data can mislead statistical analysis and model predictions.\n",
    "#     Task 1: Visualize a dataset and identify outliers using a boxplot.\n",
    "#     Task 2: Remove or adjust outliers and re-analyze the dataset.\n",
    "#     Task 3: Research and report on a technique for handling outliers effectively.\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Dataset:\n",
      "    Age     Salary  Gender\n",
      "0    25    50000.0    Male\n",
      "1    30    60000.0  Female\n",
      "2    22    52000.0  Female\n",
      "3   NaN    58000.0    Male\n",
      "4    28        NaN    Male\n",
      "5    30    60000.0  Female\n",
      "6    22    52000.0  Female\n",
      "7   100  1000000.0    Male\n",
      "8    35    62000.0  Female\n",
      "9    40    58000.0  Female\n",
      "10   28    58000.0  Female\n",
      "11   30    60000.0  Female\n",
      "\n",
      "Missing Values by Column:\n",
      "Age       1\n",
      "Salary    1\n",
      "Gender    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m X1 \u001b[38;5;241m=\u001b[39m X_missing\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m     50\u001b[0m y1 \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mloc[X1\u001b[38;5;241m.\u001b[39mindex]\n\u001b[0;32m---> 51\u001b[0m X_train1, X_test1, y_train1, y_test1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m model1 \u001b[38;5;241m=\u001b[39m LinearRegression()\u001b[38;5;241m.\u001b[39mfit(X_train1, y_train1)\n\u001b[1;32m     53\u001b[0m pred1 \u001b[38;5;241m=\u001b[39m model1\u001b[38;5;241m.\u001b[39mpredict(X_test1)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2851\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2848\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2850\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2851\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2481\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2478\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2483\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2485\u001b[0m     )\n\u001b[1;32m   2487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ------------------------------\n",
    "# Load Sample Dataset\n",
    "# ------------------------------\n",
    "# Simulated dataset with missing values, duplicates, incorrect types, and outliers\n",
    "data = {\n",
    "    'Age': [25, 30, 22, np.nan, 28, 30, 22, 100, 35, '40', 28],\n",
    "    'Salary': [50000, 60000, 52000, 58000, np.nan, 60000, 52000, 1000000, 62000, 58000, 58000],\n",
    "    'Gender': ['Male', 'Female', 'Female', 'Male', 'Male', 'Female', 'Female', 'Male', 'Female', 'Female', 'Female']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Introduce a duplicate row\n",
    "df = pd.concat([df, df.iloc[[1]]], ignore_index=True)\n",
    "\n",
    "print(\"\\nOriginal Dataset:\")\n",
    "print(df)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. MISSING VALUES\n",
    "# -----------------------------------------------------\n",
    "\n",
    "print(\"\\nMissing Values by Column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Task 2: Replace missing values\n",
    "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')  # Convert Age to numeric\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "df['Salary'].fillna(df['Salary'].mean(), inplace=True)\n",
    "\n",
    "# Task 3: Compare model performance\n",
    "df_model = df.copy()\n",
    "df_model['Gender'] = df_model['Gender'].map({'Male': 0, 'Female': 1})\n",
    "X = df_model[['Age', 'Gender']]\n",
    "y = df_model['Salary']\n",
    "\n",
    "# With missing values (before filling)\n",
    "X_missing = X.copy()\n",
    "X_missing.loc[3, 'Age'] = np.nan\n",
    "X_missing.loc[4, 'Salary'] = np.nan\n",
    "\n",
    "X1 = X_missing.dropna()\n",
    "y1 = y.loc[X1.index]\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=1)\n",
    "model1 = LinearRegression().fit(X_train1, y_train1)\n",
    "pred1 = model1.predict(X_test1)\n",
    "print(\"\\nMSE without handling missing values:\", mean_squared_error(y_test1, pred1))\n",
    "\n",
    "# After handling missing values\n",
    "X2 = X\n",
    "y2 = y\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=1)\n",
    "model2 = LinearRegression().fit(X_train2, y_train2)\n",
    "pred2 = model2.predict(X_test2)\n",
    "print(\"MSE after handling missing values:\", mean_squared_error(y_test2, pred2))\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. DUPLICATE DATA\n",
    "# -----------------------------------------------------\n",
    "\n",
    "print(\"\\nBefore removing duplicates:\", df.shape)\n",
    "df = df.drop_duplicates()\n",
    "print(\"After removing duplicates:\", df.shape)\n",
    "\n",
    "# Task 3: Explain duplication effect\n",
    "print(\"\\nExplanation: Duplicate data biases model learning toward repeated samples, causing overfitting and distorted predictions.\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. INCORRECT DATA TYPES\n",
    "# -----------------------------------------------------\n",
    "\n",
    "print(\"\\nData Types Before Correction:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Task 1 & 2: Convert string numbers to int\n",
    "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')  # Convert to float\n",
    "df['Age'] = df['Age'].astype(int)\n",
    "\n",
    "print(\"\\nData Types After Correction:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Task 3: Explanation\n",
    "print(\"\\nCorrect data types ensure mathematical operations, encoding, and feature generation behave as expected.\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. OUTLIERS & INCONSISTENCIES\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# Task 1: Visualize with boxplot\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x=df['Salary'])\n",
    "plt.title(\"Boxplot of Salary\")\n",
    "plt.show()\n",
    "\n",
    "# Task 2: Remove outliers using IQR\n",
    "Q1 = df['Salary'].quantile(0.25)\n",
    "Q3 = df['Salary'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[(df['Salary'] >= lower_bound) & (df['Salary'] <= upper_bound)]\n",
    "print(\"\\nAfter removing outliers:\", df.shape)\n",
    "\n",
    "# Task 3: Research Report\n",
    "print(\"\\nTechnique: IQR (Interquartile Range) method effectively handles outliers by trimming values outside 1.5x IQR range. Other methods include Z-Score, Isolation Forest, or Winsorization.\")\n",
    "\n",
    "# Final cleaned dataset\n",
    "print(\"\\nFinal Cleaned Dataset:\")\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
