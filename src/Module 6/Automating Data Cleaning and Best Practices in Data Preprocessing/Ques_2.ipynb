{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Task: Complete Pipeline for a Dataset\n",
    "1. Objective: Build a complex pipeline with multiple transformations.\n",
    "2. Steps:\n",
    "    - Load a sample dataset.\n",
    "    - Define a transformation pipeline with both imputation and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Imputation Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Scaling Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combined Transformation Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed numerical columns:\n",
      "    ID     Price  Avg ratings  Total ratings  Delivery time\n",
      "0  0.0 -0.209783     1.150256      -0.144689       0.352164\n",
      "1  0.0 -0.209783     0.687001      -0.144689       0.142249\n",
      "2  0.0  1.305849     1.150256      -0.144689      -0.277581\n",
      "3  0.0 -0.426302     0.378165       0.877217       0.212220\n",
      "4  0.0  0.006736     0.532583      -0.272427       0.632050\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(\"swiggy.csv\")\n",
    "\n",
    "# Step 2: Automatically detect numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Step 3: Handle case where no numerical columns found\n",
    "if not numerical_cols:\n",
    "    raise ValueError(\"No numerical columns found in the dataset!\")\n",
    "\n",
    "# Optional: Simulate missing values for demo\n",
    "df.loc[0:5, numerical_cols[0]] = np.nan  # Add missing values to first numeric column\n",
    "\n",
    "# Step 4: Define pipeline for imputation and scaling\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Step 5: Create column transformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 6: Apply transformations and create a new DataFrame\n",
    "df_transformed = preprocessor.fit_transform(df[numerical_cols])\n",
    "df[numerical_cols] = pd.DataFrame(df_transformed, columns=numerical_cols)\n",
    "\n",
    "# Step 7: View the transformed data\n",
    "print(\"Transformed numerical columns:\")\n",
    "print(df[numerical_cols].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
