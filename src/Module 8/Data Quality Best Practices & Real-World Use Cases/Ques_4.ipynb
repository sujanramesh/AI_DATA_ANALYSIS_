{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Healthcare â€“ Patient Data Accuracy\n",
    "\n",
    "**Task 1**: Patient Record Accuracy Assessment\n",
    "\n",
    "**Objective**: Achieve high accuracy in patient records.\n",
    "\n",
    "**Steps**:\n",
    "1. Examine a sample patient dataset for common inaccuracies.\n",
    "2. Identify at least three common issues, such as medication errors or misdiagnoses.\n",
    "3. Propose validation measures to ensure data accuracy at the point of entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**: Implement Healthcare Data Quality Checks\n",
    "\n",
    "**Objective**: Maintain accurate health records within a healthcare system.\n",
    "\n",
    "**Steps**:\n",
    "1. Develop a validation workflow for patient data.\n",
    "2. Use appropriate software to automate checks for common errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DataContext' from 'great_expectations.data_context' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/data_context/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mge\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataContext\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshutil\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DataContext' from 'great_expectations.data_context' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/data_context/__init__.py)"
     ]
    }
   ],
   "source": [
    "# This script demonstrates how to automate data quality checks using Great Expectations.\n",
    "# It covers setting up a data context, defining expectations, validating data,\n",
    "# and generating data quality reports.\n",
    "\n",
    "# --- Prerequisites ---\n",
    "# Before running this code, you need to install Great Expectations.\n",
    "# Open your terminal or command prompt and run:\n",
    "# pip install great_expectations pandas\n",
    "\n",
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "from great_expectations.data_context import DataContext\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Define a directory for the Great Expectations project.\n",
    "# This will create a 'great_expectations' subdirectory in your current working directory.\n",
    "ge_project_dir = \"my_ge_project\"\n",
    "\n",
    "# Clean up previous GE project if it exists for a fresh start\n",
    "if os.path.exists(ge_project_dir):\n",
    "    print(f\"Removing existing Great Expectations project directory: {ge_project_dir}\")\n",
    "    shutil.rmtree(ge_project_dir)\n",
    "\n",
    "# Initialize a Great Expectations data context.\n",
    "# This creates the 'great_expectations' directory with configuration files.\n",
    "print(f\"Initializing Great Expectations data context in '{ge_project_dir}'...\")\n",
    "context = ge.data_context.DataContext.create(project_dir=ge_project_dir)\n",
    "print(\"Great Expectations data context initialized.\")\n",
    "\n",
    "# --- Previous Tasks (Customer Data) ---\n",
    "\n",
    "print(\"\\n--- Previous Tasks: Customer Data Validation ---\")\n",
    "\n",
    "# Create a sample customer dataset\n",
    "print(\"\\nCreating a sample customer dataset...\")\n",
    "data_customer = {\n",
    "    'customer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 11], # Duplicate customer_id 1\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', 'Grace', 'Heidi', 'Ivan', 'Judy', 'Alice', 'Kyle'],\n",
    "    'email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'david@example.com', 'eve@example.com',\n",
    "              'frank@example.com', 'grace@example.com', 'heidi@example.com', 'ivan@example.com', 'judy@example.com',\n",
    "              'alice@example.com', 'kyle@example.com'],\n",
    "    'age': [25, 30, 35, 40, 28, 32, 29, 45, 22, 38, 25, None], # Missing age for Kyle\n",
    "    'city': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'Philadelphia', 'San Antonio', 'San Diego', 'Dallas', 'San Jose', 'New York', 'Austin'],\n",
    "    'registration_date': ['2023-01-15', '2022-03-20', '2023-07-01', '2021-11-10', '2023-02-28',\n",
    "                          '2022-09-05', '2023-04-12', '2021-06-30', '2023-05-18', '2022-01-01',\n",
    "                          '2023-01-15', '2023-10-25'],\n",
    "    'order_count': [5, 12, 8, 20, 3, 15, 7, 25, 2, 10, 5, 6],\n",
    "    'is_active': [True, True, False, True, True, False, True, True, True, False, True, True]\n",
    "}\n",
    "df_customer = pd.DataFrame(data_customer)\n",
    "print(\"Customer Data (first 5 rows):\")\n",
    "print(df_customer.head())\n",
    "\n",
    "# Add customer DataFrame to a Great Expectations Data Source\n",
    "datasource_name_customer = \"customer_data_source\"\n",
    "data_asset_name_customer = \"customer_records\"\n",
    "\n",
    "context.add_datasource(\n",
    "    name=datasource_name_customer,\n",
    "    class_name=\"PandasDatasource\",\n",
    "    batch_spec_passthrough={\"reader_method\": \"dataframe\"},\n",
    ")\n",
    "\n",
    "batch_request_customer = ge.core.batch_request.BatchRequest(\n",
    "    datasource_name=datasource_name_customer,\n",
    "    data_asset_name=data_asset_name_customer,\n",
    "    data_connector_name=\"default_runtime_data_connector\",\n",
    "    data_connector_query={\"batch_filter_parameters\": {\"batch_data\": df_customer}},\n",
    ")\n",
    "validator_customer = context.get_validator(\n",
    "    batch_request=batch_request_customer,\n",
    "    expectation_suite_name=\"customer_data_suite\"\n",
    ")\n",
    "\n",
    "print(\"\\nCreating basic expectations for customer dataset...\")\n",
    "validator_customer.expect_column_to_exist(\"customer_id\")\n",
    "validator_customer.expect_column_values_to_be_of_type(\"customer_id\", \"int\")\n",
    "validator_customer.expect_column_values_to_be_unique(\"customer_id\") # Added unique for customer_id\n",
    "validator_customer.expect_column_to_exist(\"name\")\n",
    "validator_customer.expect_column_values_to_be_of_type(\"name\", \"str\")\n",
    "validator_customer.expect_column_to_exist(\"age\")\n",
    "validator_customer.expect_column_values_to_be_of_type(\"age\", \"int\")\n",
    "validator_customer.expect_column_values_to_be_between(\"age\", min_value=18, max_value=99, allow_missing=True)\n",
    "validator_customer.expect_column_to_exist(\"email\")\n",
    "validator_customer.expect_column_values_to_match_regex(\"email\", r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\")\n",
    "validator_customer.expect_column_to_exist(\"registration_date\")\n",
    "validator_customer.expect_column_values_to_match_strftime_format(\"registration_date\", \"%Y-%m-%d\")\n",
    "validator_customer.expect_column_to_exist(\"order_count\")\n",
    "validator_customer.expect_column_values_to_be_of_type(\"order_count\", \"int\")\n",
    "validator_customer.expect_column_values_to_be_between(\"order_count\", min_value=0, max_value=None)\n",
    "validator_customer.expect_column_to_exist(\"is_active\")\n",
    "validator_customer.expect_column_values_to_be_of_type(\"is_active\", \"bool\")\n",
    "\n",
    "# Save the customer expectation suite\n",
    "validator_customer.save_expectation_suite(discard_failed_expectations=False)\n",
    "print(\"Customer expectation suite 'customer_data_suite' saved.\")\n",
    "\n",
    "# Run validation for customer data\n",
    "checkpoint_name_customer = \"customer_data_checkpoint\"\n",
    "context.add_checkpoint(\n",
    "    name=checkpoint_name_customer,\n",
    "    validator=validator_customer,\n",
    "    action_list=[\n",
    "        {\"name\": \"store_validation_result\", \"action_class\": \"StoreValidationResultAction\"},\n",
    "        {\"name\": \"store_evaluation_parameter_metrics\", \"action_class\": \"StoreEvaluationParametersAction\"},\n",
    "        {\"name\": \"update_data_docs\", \"action_class\": \"UpdateDataDocsAction\"},\n",
    "    ],\n",
    ")\n",
    "validation_result_customer = context.run_checkpoint(checkpoint_name=checkpoint_name_customer)\n",
    "\n",
    "print(\"\\nCustomer Data Validation Results Summary:\")\n",
    "if validation_result_customer.success:\n",
    "    print(\"Customer data validation successful! All expectations passed.\")\n",
    "else:\n",
    "    print(\"Customer data validation failed. Some expectations did not pass.\")\n",
    "    for result in validation_result_customer.results:\n",
    "        if not result.success:\n",
    "            print(f\"  Failed Expectation: {result.expectation_config.expectation_type} for column '{result.expectation_config.column}'\")\n",
    "            if result.expectation_config.column: # Check if column is in the expectation config\n",
    "                print(f\"    for column '{result.expectation_config.column}'\")\n",
    "            print(f\"    Details: {result.result}\")\n",
    "\n",
    "# --- Previous Task: Finance â€“ Ensuring Accurate Transactions ---\n",
    "\n",
    "print(\"\\n--- Previous Task: Finance â€“ Ensuring Accurate Transactions ---\")\n",
    "\n",
    "# Create a sample financial transaction dataset\n",
    "print(\"\\nCreating a sample financial transaction dataset...\")\n",
    "data_transactions = {\n",
    "    'transaction_id': ['T001', 'T002', 'T003', 'T004', 'T005', 'T006', 'T007', 'T001'], # Duplicate T001\n",
    "    'transaction_date': ['2023-01-01', '2023-01-05', '2023-01-10', '2023-01-15', '2023-01-20', '2023-01-25', '2023-01-30', '2023-01-01'],\n",
    "    'account_id': ['ACC001', 'ACC002', 'ACC001', 'ACC003', 'ACC002', 'ACC004', 'ACC001', 'ACC001'],\n",
    "    'transaction_type': ['DEBIT', 'CREDIT', 'DEBIT', 'CREDIT', 'DEBIT', 'TRANSFER', 'DEBIT', 'DEBIT'],\n",
    "    'amount': [100.50, 250.00, 50.25, 120.00, -30.00, 75.00, 200.00, 100.50], # Negative amount\n",
    "    'currency': ['USD', 'USD', 'EUR', 'USD', 'USD', 'GBP', 'USD', 'USD'],\n",
    "    'description': ['Groceries', 'Salary', 'Rent', 'Utilities', 'Refund', 'Online Purchase', None, 'Groceries'] # Missing description\n",
    "}\n",
    "df_transactions = pd.DataFrame(data_transactions)\n",
    "print(\"Financial Transaction Data (first 5 rows):\")\n",
    "print(df_transactions.head())\n",
    "\n",
    "# Add transaction DataFrame to a Great Expectations Data Source\n",
    "datasource_name_transactions = \"financial_data_source\"\n",
    "data_asset_name_transactions = \"transactions\"\n",
    "\n",
    "context.add_datasource(\n",
    "    name=datasource_name_transactions,\n",
    "    class_name=\"PandasDatasource\",\n",
    "    batch_spec_passthrough={\"reader_method\": \"dataframe\"},\n",
    ")\n",
    "\n",
    "batch_request_transactions = ge.core.batch_request.BatchRequest(\n",
    "    datasource_name=datasource_name_transactions,\n",
    "    data_asset_name=data_asset_name_transactions,\n",
    "    data_connector_name=\"default_runtime_data_connector\",\n",
    "    data_connector_query={\"batch_filter_parameters\": {\"batch_data\": df_transactions}},\n",
    ")\n",
    "validator_transactions = context.get_validator(\n",
    "    batch_request=batch_request_transactions,\n",
    "    expectation_suite_name=\"financial_transactions_suite\"\n",
    ")\n",
    "\n",
    "print(\"\\nDeveloping validation checks for financial transactions...\")\n",
    "validator_transactions.expect_column_to_exist(\"transaction_id\")\n",
    "validator_transactions.expect_column_values_to_be_unique(\"transaction_id\")\n",
    "validator_transactions.expect_column_to_exist(\"transaction_date\")\n",
    "validator_transactions.expect_column_values_to_match_strftime_format(\"transaction_date\", \"%Y-%m-%d\")\n",
    "validator_transactions.expect_column_to_exist(\"account_id\")\n",
    "validator_transactions.expect_column_values_to_be_of_type(\"account_id\", \"str\")\n",
    "validator_transactions.expect_column_values_to_match_regex(\"account_id\", r\"^ACC\\d{3}$\") # e.g., ACC001\n",
    "validator_transactions.expect_column_to_exist(\"transaction_type\")\n",
    "validator_transactions.expect_column_values_to_be_in_set(\"transaction_type\", [\"DEBIT\", \"CREDIT\", \"TRANSFER\", \"FEE\"])\n",
    "validator_transactions.expect_column_to_exist(\"amount\")\n",
    "validator_transactions.expect_column_values_to_be_of_type(\"amount\", \"float\")\n",
    "validator_transactions.expect_column_values_to_be_between(\"amount\", min_value=0.01, max_value=None) # Amount must be positive\n",
    "validator_transactions.expect_column_to_exist(\"currency\")\n",
    "validator_transactions.expect_column_values_to_be_in_set(\"currency\", [\"USD\", \"EUR\", \"GBP\", \"JPY\"])\n",
    "validator_transactions.expect_column_to_exist(\"description\")\n",
    "validator_transactions.expect_column_values_to_not_be_null(\"description\", mostly=0.90)\n",
    "validator_transactions.expect_compound_columns_to_be_unique([\"transaction_id\", \"transaction_date\", \"account_id\", \"amount\"])\n",
    "\n",
    "# Save the financial transaction expectation suite\n",
    "validator_transactions.save_expectation_suite(discard_failed_expectations=False)\n",
    "print(\"Financial transaction expectation suite 'financial_transactions_suite' saved.\")\n",
    "\n",
    "# Run validation for financial data\n",
    "checkpoint_name_transactions = \"financial_transactions_checkpoint\"\n",
    "context.add_checkpoint(\n",
    "    name=checkpoint_name_transactions,\n",
    "    validator=validator_transactions,\n",
    "    action_list=[\n",
    "        {\"name\": \"store_validation_result\", \"action_class\": \"StoreValidationResultAction\"},\n",
    "        {\"name\": \"store_evaluation_parameter_metrics\", \"action_class\": \"StoreEvaluationParametersAction\"},\n",
    "        {\"name\": \"update_data_docs\", \"action_class\": \"UpdateDataDocsAction\"},\n",
    "    ],\n",
    ")\n",
    "validation_result_transactions = context.run_checkpoint(checkpoint_name=checkpoint_name_transactions)\n",
    "\n",
    "print(\"\\nFinancial Transaction Validation Results Summary:\")\n",
    "if validation_result_transactions.success:\n",
    "    print(\"Financial transaction validation successful! All expectations passed.\")\n",
    "else:\n",
    "    print(\"Financial transaction validation failed. Some expectations did not pass.\")\n",
    "    for result in validation_result_transactions.results:\n",
    "        if not result.success:\n",
    "            print(f\"  Failed Expectation: {result.expectation_config.expectation_type} for column '{result.expectation_config.column}'\")\n",
    "            if result.expectation_config.column:\n",
    "                print(f\"    for column '{result.expectation_config.column}'\")\n",
    "            print(f\"    Details: {result.result}\")\n",
    "\n",
    "\n",
    "# --- New Task: Healthcare â€“ Patient Data Accuracy ---\n",
    "\n",
    "print(\"\\n--- New Task: Healthcare â€“ Patient Data Accuracy ---\")\n",
    "\n",
    "# Task 1: Patient Record Accuracy Assessment\n",
    "\n",
    "print(\"\\n--- Task 1: Patient Record Accuracy Assessment ---\")\n",
    "\n",
    "# 1. Examine a sample patient dataset for common inaccuracies.\n",
    "print(\"\\nCreating a sample patient dataset...\")\n",
    "data_patients = {\n",
    "    'patient_id': ['P001', 'P002', 'P003', 'P004', 'P005', 'P001', 'P006'], # Duplicate P001\n",
    "    'first_name': ['John', 'Jane', 'Peter', 'Mary', 'Alice', 'John', 'Robert'],\n",
    "    'last_name': ['Doe', 'Smith', 'Jones', 'Brown', 'Williams', 'Doe', 'Johnson'],\n",
    "    'date_of_birth': ['1980-05-10', '1992-11-23', '1975-01-01', '2000-03-15', '1968-09-02', '1980-05-10', '1995-07-20'],\n",
    "    'gender': ['Male', 'Female', 'Male', 'Female', 'MALE', 'Male', 'Non-binary'], # Inconsistent 'MALE'\n",
    "    'diagnosis': ['Flu', 'Common Cold', 'Hypertension', 'Diabetes', 'Arthritis', 'Flu', 'Asthma'],\n",
    "    'medication': ['Amoxicillin', 'N/A', 'Lisinopril', 'Metformin', 'Ibuprofen', 'Amoxicillin', 'Ventolin'],\n",
    "    'last_visit_date': ['2024-01-20', '2025-02-15', '2024-03-01', '2025-04-10', '2024-05-05', '2024-01-20', '2025-01-01'],\n",
    "    'blood_pressure_systolic': [120, 110, 145, 130, 160, 120, 125], # High BP for P005\n",
    "    'blood_pressure_diastolic': [80, 70, 95, 85, 100, 80, 80],     # High BP for P005\n",
    "    'allergies': ['Penicillin', None, 'None', 'Sulfur', 'Latex', 'Penicillin', 'Pollen'] # Missing allergies\n",
    "}\n",
    "df_patients = pd.DataFrame(data_patients)\n",
    "print(\"Patient Data (first 5 rows):\")\n",
    "print(df_patients.head())\n",
    "\n",
    "# 2. Identify at least three common issues, such as medication errors or misdiagnoses.\n",
    "print(\"\\nIdentifying common inaccuracies in patient records:\")\n",
    "print(\" - Duplicate Patient IDs: 'P001' appears twice, indicating potential duplicate records.\")\n",
    "print(\" - Inconsistent 'gender' entries: 'Male' vs 'MALE', and 'Non-binary' which might not be an allowed value.\")\n",
    "print(\" - Medication errors/inconsistencies: 'N/A' for medication, and `None` for allergies.\")\n",
    "print(\" - Out-of-range values: Blood pressure values might be outside typical healthy ranges (e.g., very high/low).\")\n",
    "print(\" - Missing values: 'allergies' column has `None`.\")\n",
    "print(\" - Date inconsistencies: 'date_of_birth' and 'last_visit_date' could have future dates or illogical sequences.\")\n",
    "\n",
    "# 3. Propose validation measures to ensure data accuracy at the point of entry.\n",
    "print(\"\\nProposing validation measures for patient data accuracy at point of entry:\")\n",
    "print(\" - **Unique Identifiers**: Ensure `patient_id` is unique upon creation.\")\n",
    "print(\" - **Data Type & Format Checks**: Verify dates are valid dates, names are strings, etc.\")\n",
    "print(\" - **Lookup/Controlled Vocabularies**: Restrict `gender`, `diagnosis`, `medication` to predefined, valid lists.\")\n",
    "print(\" - **Range Checks**: Validate numerical fields like `blood_pressure_systolic/diastolic` within acceptable medical ranges.\")\n",
    "print(\" - **Conditional Logic**: If `diagnosis` is 'Diabetes', then `medication` should likely include 'Metformin' or similar, or at least not be 'N/A'.\")\n",
    "print(\" - **Completeness**: Ensure critical fields like `first_name`, `last_name`, `date_of_birth` are not null.\")\n",
    "print(\" - **Referential Integrity**: If linking to another table (e.g., doctor_id), ensure the foreign key exists.\")\n",
    "print(\" - **Historical Consistency**: Ensure `last_visit_date` is not before `date_of_birth` or previous visit dates.\")\n",
    "\n",
    "\n",
    "# Task 2: Implement Healthcare Data Quality Checks\n",
    "\n",
    "print(\"\\n--- Task 2: Implement Healthcare Data Quality Checks ---\")\n",
    "\n",
    "# 1. Develop a validation workflow for patient data.\n",
    "# This involves adding the DataFrame to GE and defining an expectation suite.\n",
    "datasource_name_patients = \"patient_data_source\"\n",
    "data_asset_name_patients = \"patient_records\"\n",
    "\n",
    "context.add_datasource(\n",
    "    name=datasource_name_patients,\n",
    "    class_name=\"PandasDatasource\",\n",
    "    batch_spec_passthrough={\"reader_method\": \"dataframe\"},\n",
    ")\n",
    "\n",
    "batch_request_patients = ge.core.batch_request.BatchRequest(\n",
    "    datasource_name=datasource_name_patients,\n",
    "    data_asset_name=data_asset_name_patients,\n",
    "    data_connector_name=\"default_runtime_data_connector\",\n",
    "    data_connector_query={\"batch_filter_parameters\": {\"batch_data\": df_patients}},\n",
    ")\n",
    "validator_patients = context.get_validator(\n",
    "    batch_request=batch_request_patients,\n",
    "    expectation_suite_name=\"patient_data_suite\"\n",
    ")\n",
    "\n",
    "# 2. Use appropriate software to automate checks for common errors. (Using Great Expectations)\n",
    "print(\"\\nAutomating checks for common patient data errors using Great Expectations...\")\n",
    "\n",
    "# Expectation: `patient_id` is unique and not null\n",
    "validator_patients.expect_column_to_exist(\"patient_id\")\n",
    "validator_patients.expect_column_values_to_be_unique(\"patient_id\")\n",
    "validator_patients.expect_column_values_to_not_be_null(\"patient_id\")\n",
    "\n",
    "# Expectation: Names are strings and not null\n",
    "validator_patients.expect_column_to_exist(\"first_name\")\n",
    "validator_patients.expect_column_values_to_be_of_type(\"first_name\", \"str\")\n",
    "validator_patients.expect_column_values_to_not_be_null(\"first_name\")\n",
    "validator_patients.expect_column_to_exist(\"last_name\")\n",
    "validator_patients.expect_column_values_to_be_of_type(\"last_name\", \"str\")\n",
    "validator_patients.expect_column_values_to_not_be_null(\"last_name\")\n",
    "\n",
    "# Expectation: `date_of_birth` is a valid date format and not in the future\n",
    "validator_patients.expect_column_to_exist(\"date_of_birth\")\n",
    "validator_patients.expect_column_values_to_match_strftime_format(\"date_of_birth\", \"%Y-%m-%d\")\n",
    "# Custom expectation for future dates:\n",
    "# First convert to datetime to compare\n",
    "df_patients['date_of_birth_dt'] = pd.to_datetime(df_patients['date_of_birth'], errors='coerce')\n",
    "current_date_ts = pd.Timestamp(datetime.now().strftime('%Y-%m-%d'))\n",
    "validator_patients.expect_column_values_to_be_between(\n",
    "    \"date_of_birth_dt\",\n",
    "    min_value=pd.Timestamp('1900-01-01'), # A reasonable historical start date\n",
    "    max_value=current_date_ts,\n",
    "    parse_strings_as_datetimes=False # Already converted\n",
    ")\n",
    "\n",
    "# Expectation: `gender` is from a controlled vocabulary and consistent casing\n",
    "validator_patients.expect_column_to_exist(\"gender\")\n",
    "validator_patients.expect_column_values_to_be_in_set(\"gender\", [\"Male\", \"Female\", \"Other\", \"Unknown\"])\n",
    "validator_patients.expect_column_values_to_match_regex(\"gender\", r\"^(Male|Female|Other|Unknown)$\") # For exact matching/casing\n",
    "\n",
    "# Expectation: `diagnosis` is not null and is a string\n",
    "validator_patients.expect_column_to_exist(\"diagnosis\")\n",
    "validator_patients.expect_column_values_to_not_be_null(\"diagnosis\")\n",
    "validator_patients.expect_column_values_to_be_of_type(\"diagnosis\", \"str\")\n",
    "\n",
    "# Expectation: `medication` is not null for a high percentage of records\n",
    "validator_patients.expect_column_to_exist(\"medication\")\n",
    "validator_patients.expect_column_values_to_not_be_null(\"medication\", mostly=0.95) # Allow some N/A or None\n",
    "\n",
    "# Expectation: `last_visit_date` is a valid date and not in the future, and after DOB\n",
    "validator_patients.expect_column_to_exist(\"last_visit_date\")\n",
    "validator_patients.expect_column_values_to_match_strftime_format(\"last_visit_date\", \"%Y-%m-%d\")\n",
    "# Again, convert to datetime for comparison\n",
    "df_patients['last_visit_date_dt'] = pd.to_datetime(df_patients['last_visit_date'], errors='coerce')\n",
    "validator_patients.expect_column_values_to_be_between(\n",
    "    \"last_visit_date_dt\",\n",
    "    min_value=pd.Timestamp('1900-01-01'), # Should be after DOB, but check overall range\n",
    "    max_value=current_date_ts,\n",
    "    parse_strings_as_datetimes=False\n",
    ")\n",
    "# Expect `last_visit_date` to be after `date_of_birth`\n",
    "# This requires comparing two columns, which can be done using `expect_column_pair_values_to_be_date_and_time_consistent`\n",
    "# or by explicitly checking in a custom expectation.\n",
    "# For simplicity and common GE expectations:\n",
    "validator_patients.expect_column_A_values_to_be_greater_than_B_values(\n",
    "    column_A=\"last_visit_date_dt\",\n",
    "    column_B=\"date_of_birth_dt\",\n",
    "    or_equal=True, # A visit can theoretically be on the birth date for new borns\n",
    "    parse_strings_as_datetimes=False\n",
    ")\n",
    "\n",
    "# Expectation: Blood pressure values are within reasonable medical ranges\n",
    "validator_patients.expect_column_to_exist(\"blood_pressure_systolic\")\n",
    "validator_patients.expect_column_values_to_be_between(\"blood_pressure_systolic\", min_value=70, max_value=200) # Typical ranges\n",
    "validator_patients.expect_column_to_exist(\"blood_pressure_diastolic\")\n",
    "validator_patients.expect_column_values_to_be_between(\"blood_pressure_diastolic\", min_value=40, max_value=120) # Typical ranges\n",
    "# Expect systolic to be greater than diastolic\n",
    "validator_patients.expect_column_A_values_to_be_greater_than_B_values(\n",
    "    column_A=\"blood_pressure_systolic\",\n",
    "    column_B=\"blood_pressure_diastolic\"\n",
    ")\n",
    "\n",
    "# Expectation: Allergies column exists and not null for a majority\n",
    "validator_patients.expect_column_to_exist(\"allergies\")\n",
    "validator_patients.expect_column_values_to_not_be_null(\"allergies\", mostly=0.80) # Allow some missing\n",
    "\n",
    "# Save the patient data expectation suite\n",
    "validator_patients.save_expectation_suite(discard_failed_expectations=False)\n",
    "print(\"Patient data expectation suite 'patient_data_suite' saved.\")\n",
    "\n",
    "# Run validation for patient data\n",
    "checkpoint_name_patients = \"patient_data_checkpoint\"\n",
    "context.add_checkpoint(\n",
    "    name=checkpoint_name_patients,\n",
    "    validator=validator_patients,\n",
    "    action_list=[\n",
    "        {\"name\": \"Store_validation_result\", \"action_class\": \"StoreValidationResultAction\"},\n",
    "        {\"name\": \"store_evaluation_parameter_metrics\", \"action_class\": \"StoreEvaluationParametersAction\"},\n",
    "        {\"name\": \"update_data_docs\", \"action_class\": \"UpdateDataDocsAction\"},\n",
    "    ],\n",
    ")\n",
    "validation_result_patients = context.run_checkpoint(checkpoint_name=checkpoint_name_patients)\n",
    "\n",
    "print(\"\\nPatient Data Validation Results Summary:\")\n",
    "if validation_result_patients.success:\n",
    "    print(\"Patient data validation successful! All expectations passed.\")\n",
    "else:\n",
    "    print(\"Patient data validation failed. Some expectations did not pass.\")\n",
    "    for result in validation_result_patients.results:\n",
    "        if not result.success:\n",
    "            print(f\"  Failed Expectation: {result.expectation_config.expectation_type}\")\n",
    "            if result.expectation_config.column:\n",
    "                print(f\"    for column '{result.expectation_config.column}'\")\n",
    "            print(f\"    Details: {result.result}\")\n",
    "\n",
    "\n",
    "# Open Data Docs to review all validation reports\n",
    "print(\"\\nOpening data Docs to review all validation reports...\")\n",
    "context.open_data_docs()\n",
    "print(\"Data Docs report generated and opened in your browser (if supported by your environment).\")\n",
    "\n",
    "# --- Conceptual: Automate Periodic Checks (Scheduling) ---\n",
    "\n",
    "print(\"\\n--- Conceptual: Automating Periodic Checks (Scheduling) ---\")\n",
    "print(\"Great Expectations validations for customer, financial, and patient data can be automated using various scheduling tools.\")\n",
    "print(\"This part is conceptual as it involves external tools or frameworks.\")\n",
    "\n",
    "print(\"\\n1. Cron Jobs (Linux/macOS) / Task Scheduler (Windows):\")\n",
    "print(\"   You can set up a cron job to run this Python script at a specific interval (e.g., daily).\")\n",
    "print(\"   Example cron entry (runs daily at 2 AM):\")\n",
    "print(f\"   0 2 * * * /usr/bin/python3 {os.path.abspath(__file__)}\")\n",
    "\n",
    "print(\"\\n2. Apache Airflow / Prefect / Dagster:\")\n",
    "print(\"   Define a DAG (Directed Acyclic Graph) in Airflow (or similar workflow in Prefect/Dagster).\")\n",
    "print(\"   Each task in the DAG could represent a data quality check for a specific dataset.\")\n",
    "print(\"   Example Airflow DAG snippet:\")\n",
    "print(\"   from airflow import DAG\")\n",
    "print(\"   from airflow.operators.python import PythonOperator\")\n",
    "print(\"   from datetime import datetime\")\n",
    "print(\"\\n   def run_ge_validation(checkpoint_name):\")\n",
    "print(\"       context = ge.data_context.DataContext(context_root_dir='my_ge_project')\")\n",
    "print(\"       validation_result = context.run_checkpoint(checkpoint_name=checkpoint_name)\")\n",
    "print(\"       if not validation_result.success:\")\n",
    "print(\"           raise ValueError(f'Validation failed for checkpoint {checkpoint_name}')\")\n",
    "print(\"\\n   with DAG('data_quality_checks', start_date=datetime(2023, 1, 1), schedule_interval='@daily') as dag:\")\n",
    "print(\"       validate_customer_data = PythonOperator(\")\n",
    "print(\"           task_id='validate_customer_data',\")\n",
    "print(\"           python_callable=run_ge_validation,\")\n",
    "print(\"           op_kwargs={'checkpoint_name': 'customer_data_checkpoint'}\")\n",
    "print(\"       )\")\n",
    "print(\"       validate_financial_data = PythonOperator(\")\n",
    "print(\"           task_id='validate_financial_data',\")\n",
    "print(\"           python_callable=run_ge_validation,\")\n",
    "print(\"           op_kwargs={'checkpoint_name': 'financial_transactions_checkpoint'}\")\n",
    "print(\"       )\")\n",
    "print(\"       validate_patient_data = PythonOperator(\")\n",
    "print(\"           task_id='validate_patient_data',\")\n",
    "print(\"           python_callable=run_ge_validation,\")\n",
    "print(\"           op_kwargs={'checkpoint_name': 'patient_data_checkpoint'}\")\n",
    "print(\"       )\")\n",
    "print(\"       # You can define task dependencies here, e.g., validate_customer_data >> validate_financial_data >> validate_patient_data\")\n",
    "\n",
    "print(\"\\n3. CI/CD Pipelines (e.g., Jenkins, GitLab CI, GitHub Actions):\")\n",
    "print(\"   Integrate Great Expectations validation into your CI/CD pipeline to ensure data quality\")\n",
    "print(\"   before deploying new data or models to production.\")\n",
    "\n",
    "print(\"\\nTo truly automate, you would integrate this script into a scheduler or orchestrator.\")\n",
    "print(\"The Data Docs can then be hosted on a web server for easy access to validation reports.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
