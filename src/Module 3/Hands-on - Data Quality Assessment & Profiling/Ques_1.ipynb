{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Load a CSV Dataset\n",
    "# Description: Load a CSV file into a Pandas DataFrame and print the first five rows to understand the structure of the dataset.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Check for Missing Values\n",
    "# Description: Identify and list the columns with missing values and the number of missing values in each.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Visualize Missing Data\n",
    "# Description: Use a heatmap to visualize the missing values in the dataset.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Remove Columns with Many Missing Values\n",
    "# Description: Drop columns that have more than 50% missing values.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: Identify Duplicate Rows\n",
    "# Description: Check for and display any duplicate rows in the dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6: Remove Duplicate Rows\n",
    "# Description: Remove duplicate rows from the dataset and verify that they have been removed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7: Check Data Inconsistencies\n",
    "# Description: Identify inconsistencies in categorical columns, such as differing text cases or trailing spaces.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 8: Get Summary of Data Quality\n",
    "# Description: Generate a summary of data quality including total records, number of duplicate rows, and columns with missing values.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 9: Generate a Data Quality Report\n",
    "# Description: Create a comprehensive data quality report that includes not only missing values but also basic statistics for numerical columns and the distribution of categorical columns.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 10: Advanced Data Imputation\n",
    "# Description: Perform advanced data imputation by replacing missing values in numerical columns with the mean and categorical columns with the mode.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully loaded from swiggy.csv\n",
      "No missing values found in the dataset.\n",
      "No missing data to visualize.\n",
      "No columns found with missing values exceeding the threshold.\n",
      "No duplicate rows found.\n",
      "No duplicate rows to remove.\n",
      "Inconsistencies found in column 'Area':\n",
      "  Unique values after cleaning: ['koramangala' 'jogupalya' 'indiranagar' 'domlur' 'cooke town'\n",
      " 'pulikeshi nagar' 'sivanchetti gardens' 'kodihalli' 'jayanagar'\n",
      " 'film nagar' 'banashankari' 'masab tank' 'banjara hills' 'andheri east'\n",
      " 'powai' 'punjagutta' 'aundh' 'baner' 'powai area' 'ramgopalpet'\n",
      " 'kalasiguda' 'adarsh nagar' 'himayatnagar' 'ashok nagar'\n",
      " 'commercial street' 'richmond town' 'vasanth nagar' 'bhowanipore'\n",
      " 'ballygunge' 'gariahat' 'kalighat' 'sion' 'mumbai' 'rajajinagar'\n",
      " 'golpark' 'shivajinagar' 'koregaon park' 'deccan gymkhana' 'karkhana'\n",
      " 'kothrud' 'erandwane' 'koti' 'dilsukhnagar' 'nagole' 'chandrapuri colony'\n",
      " 'kothapet' 'narayanguda' 'fc road' 'park street area' 'beniapukur'\n",
      " 'bidhannagar' 'new nallakunta' 'adikmet' 'amberpet' 'karve nagar'\n",
      " 'agarkar nagar' 'mundhwa' 'mohammed wadi' 'bandra area' 'paschim vihar'\n",
      " 'malleshwaram' 'lakdikapul' 'camp' 'antop hill' 'new tippasandra'\n",
      " 'bhawani peth' 'basheer bagh' 'kalyani nagar' 'shankarapura' 'elgin'\n",
      " 'kurla west' 'saki naka' 'teynampet' 'nandanam' 'langford gardens'\n",
      " 'abids' 'santacruz east' 'khairtabad' 'vishnu garden' 'beleghata'\n",
      " 'lake town' 'gopalapuram' 'alwarpet' 'mylapore'\n",
      " 'central markt punjabi bagh' 'pashan' 'south kolkata' 'kotturpuram'\n",
      " 'habsiguda' 'uppal' 'punjabi bagh' 'kasba' 'barabazar market'\n",
      " 'manicktala' 'maniktala' 'esplanade' 'kankurgachi' 'thousand lights'\n",
      " 'taltala' 'west marredpally' 'powaiandheri east' 'nungambakkam'\n",
      " 'murad nagar' 'redhills' 'vadapalani' 'garfa' 'kondhwa' 't. nagar'\n",
      " 'marol sakinaka' 'pitampura' 'pitam pura' 'near rupbani cinema'\n",
      " 'east kolkata township' 'somajiguda' 'anna nagar' 'kilpauk' 'rohini'\n",
      " 'sector 7 rohini' 'sector 8 rohini' 'prashant vihar rohini'\n",
      " 'sector 14 rohini' 'shyam bazar' 'jodhpur park' 'kachiguda'\n",
      " 'visharant wadi' 'bkc' 'near 7 point crossing' 'gultekdi' 'hadapsar'\n",
      " 'kodambakkam' 'bibwewadi' 'khar west' 'gandhi nagar' 'chembur'\n",
      " 'sector 11 rohini' 'wanowrie' 'kasba peth' 'royapettah'\n",
      " 'sector 10 rohini' 'college square' 'shalimar bagh' 'jayamahal'\n",
      " 'new alipore' 'chetpet' 'madhura nagar' 'aminjikarai' 'wadgaon sheri'\n",
      " 'anand nagar' 'dum dum' 'poongavanapuram' 'egmore' 'yerawada'\n",
      " 'choolaimedu' 'sadashiv peth' 'sangamvadi' 'shobhabazar' 'tangra'\n",
      " 'opp padmashree movie hall' 'sarat bose rd' 'purasaiwakkam' 'cit nagar'\n",
      " 'annanagar east' 'chennai' 'ghatkopar east' 'ganganagar' 'huda complex'\n",
      " 'ramesh nagar' 'tiljala' 'near city centre 1 petrol pump' 'west mambalam'\n",
      " 'delhi' 'narhe' 'bentinck st.' 'shyambazar crossing' 'near gurudas park'\n",
      " 'machuabazar' 'sinhgad road' 'mangawadi' 'shaniwar peth' 'bowbazar'\n",
      " 'alipore' 'central market punjabi bagh' 'ghatkopar west'\n",
      " 'anna nagar west extension' 'kurla' 'old sangvi' 'sreebhumi'\n",
      " 'tilak nagar' 'sector 3 rohini' 'basavanagudi' 'sainik vihar'\n",
      " 'balavinayagar nagar' 'arumbakkam' 'tagore garden extension'\n",
      " 'krishna park tilak nagar' 'gokhalenagar' 'lullanagar' 'range hills'\n",
      " 'chiriamore' 'sinthee' 'kolkata' 'nampally' 'kalina' 'maharshi nagar'\n",
      " 'mukti nagar' 'central bangalore' 'dhankawadi' 'maniktala main rd'\n",
      " 'gobra' 'behra enclave paschim vihar' 'entally' 'santacruz west'\n",
      " 'jyothi nagar' 'vadgaon budruk' 'matunga' 'tarnaka' 'bopodi'\n",
      " 'mehdipatnam' 'ultadanga' 'ruby area  kasba  east kolkata township'\n",
      " 'chetla' 'toli chowki' 'central kolkata' 'himayath nagar' 'jadavpur'\n",
      " 'bandra west' 'rasta peth' 'selimpur' 'south dumdum'\n",
      " 'raja annamalai puram' 't nagar' 'shivaji nagar' 'malleswaram'\n",
      " 'central banglore' 'sector 9 rohini' 'seshadripuram' 'perambur'\n",
      " 'karam pura' 'zamistanpur' 'kurla - mumbai' 'bandra east' 'broad street'\n",
      " 'sarvagnanagar' 'bn reddy nagar' 'paikpara' 'kavadiguda' 'george town'\n",
      " 'haltu' 'sheela vihar colony' 'tingre nagar' 'ameerpet' 'dumdum'\n",
      " 'navrangpura' 'ellisbridge' 'university area' 'vastrapur' 'memnagar'\n",
      " 'college street' 'benson town' 'sector 2 rohini' 'ramdev nagar'\n",
      " 'usmanpura' 'lal bazar' 'adugodi' 'anna salai' 'lake gardens'\n",
      " 'sastri nager' 'kodungaiyur' 'ulsoor' 'triplicane' 'majestic'\n",
      " 'old malakpet' 'malakpet' 'bodakdev' 'tiretti' 'old washermanpet' 'paldi'\n",
      " 'juhapura' 'sector 13 rohini' 'sri hanuman nagar colony' 'dhakuria'\n",
      " 'chanchalguda' 'budh vihar' 'a unit of m/s cohort  ruby area'\n",
      " 'gulbai tekra' 'asalpha' 'kalas' 'danilimda' 'ahmedabad' 'gurukul'\n",
      " 'salt lake area' 'ashok vihar' 'santosh nagar' 'warje' 'jm road'\n",
      " 'saidabad' 'khokhra' 'topsia' 'ambawadi' 'baranagar' 'ejipura'\n",
      " 'royapuram' 'salunkhe vihar' 'humayun nagar' 'vishrantwadi'\n",
      " 'new mallepally' 'washermanpet' 'new malakpet' 'motera' 'thaltej'\n",
      " 'santoshpur' 'subhash nagar petrol pump' 'uttam nagar' 'govandi east'\n",
      " 'narayan peth' 'vyasarpadi' 'salt lake city' 'khanpur' 'lal darwaja'\n",
      " 'laldarwaja' 'modi colony' 'sagrampura' 'athwa' 'cossipore' 'bhadra'\n",
      " 'block gg1 vikaspuri' 'shahpur' 'piplod' 'vikhroli' 'annanagar'\n",
      " 'varachha' 'bharthana' 'bowenpally' 'ayanavaram' 'begampura'\n",
      " 'sion bhakti park' 'raja bazar' 'adajan' 'yousufguda' 'choolai'\n",
      " 'ghorpadi' 'kolathur' 'sanjeeva reddy nagar' 'vijayanagar'\n",
      " 'vijaya nagar colony' 'sector 8  rohini' 'khamasa' 'moghalpura'\n",
      " 'lal darwaza' 'charminar' 'raikhad' 'kothapet & dilsukhnagar' 'gopipura'\n",
      " 'chamrajpet' 'padmarao nagar' 'jamalia' 'vesu' 'golf green' 'palanpur'\n",
      " 'jodhpur village' 'baguihati' 'new magdalla' 'parvati paytha'\n",
      " 'ghansi bazaar' 'aliabad' 'madannapet colony' 'umarwada' 'behala'\n",
      " 'langar houz' 'khilwat' 'jam bagh' 'koramangala - bangalore'\n",
      " 'punjab bagh' 'satellite' 'shahpore' 'guru nanak nagar' 'khatodra wadi'\n",
      " 'tolichowki' 'nanpura' 'boudhanagar colony' 'dahin nagar' 'begumpet'\n",
      " 'sector 37' 'hindustan park' 'wanwadi' 'srirampura' 'sayedpura'\n",
      " 'azad nagar' 'budhwar peth' 'thirunagar signal vadapalani'\n",
      " 'annamalai colony' 'hyderabad' 'wadgaon budruk tilak road' 'amroli'\n",
      " 'tala' 'sovabazar' 'new rander road' 'palanpur jakatnaka' 'rander'\n",
      " 'chowk bazar' 'mahadev nagar tekra' 'chandrayangutta' 'dharavi'\n",
      " 'ghatkopar' 'kestopur' 'darulshifa' 'yakutpura' 'saijpur bogha' 'bhimrad'\n",
      " 'express avenue mall' 'shenoy nagar' 'moti nagar' 'sudhama nagar'\n",
      " 'pathar gatti' 'victoria layout' 'sector 6 rohini' 'hatibagan' 'sangvi'\n",
      " 'haripura' 'gaddiannaram' 'kuber nagar' 'surat' 'sector 1 rohini'\n",
      " 'isanpur' 'ganga dham' 'swargate' 'ambavadi' 'tad bun' 'park circus'\n",
      " 'hedua' 'guttahalli' 'sector 51' 'sampangiram nagar' 'parvat patiya'\n",
      " 'begampur' 'lnt mall musarambagh' 'salt lake' 'j.c.nagar'\n",
      " 'palanpur patia' 'tondiarpet' 'althan' 'vastral' 'kapodra patiya'\n",
      " 'jorasanko' 'marol' 'jubilee hills' 'wilson garden' 'phoenix mall'\n",
      " 'mukherjee nagar' 'tollygunge' 'talab katta' 'scruz bandra east' 'katraj'\n",
      " 'shah-e-alam roja' 'adajan patiya' 'ponniammanmedu' 'sakivihar' 'shyamal'\n",
      " 'near lal gate ramlal bazarsapuipara' 'dapodi' 'periyamet' 'maninagar'\n",
      " 'vijay nagar colony' 'udhna' 'gowliguda' 'asif nagar' 'santacruz'\n",
      " 'frazer town' 'magarpatta' 'sector 73' 'dudheshwar'\n",
      " 'kharkhana & trimulgherry' 'katad khana' 'balkampet' 'vakola' 'gowlipura'\n",
      " 'vatva' 'ahiritola' 'sadar bazaar' 'jogeshwari east'\n",
      " 'southern avenue gariahat' 'kothapet & dilshuknagar' 'navsari bazaar'\n",
      " 'viveka nagar' 'vikhroli west' 'kondhwa budruk' 'dabholi'\n",
      " 'athwa station road' 'burrabazar' 'mmda colony' 'nava vadaj' 'narolgam'\n",
      " 'villivakkam' 'nacharam' 'drive in road' 'someshwarpura' 'broadway mall'\n",
      " 'nana varachha' 'purba barisha' 'mota varachha' 'narayan nagar'\n",
      " 'jivraj park' 'sampangi rama nagar' 'brindavan colony' 'sherkotda'\n",
      " 'sheshadripuram' '26' 'sec-9 rohini' 'kiran nagar' 'neelasandra' 'ranip'\n",
      " 'garodia nagar' 'b.b.d. bagh' 'vile parle' 'pacific mall subhash nagar'\n",
      " 'dum dum park' 'malkajgiri' 'jodhpur' 'bally' 'bavdhan' 'acher'\n",
      " 'chintadripet' 'madhavaram' 'ea mall royapettah' 'nagerbazar' 'chickpet'\n",
      " 'new gayatri nagar' 'rajouri garden' 'narotam nagar' 'kustia' 'lb nagar'\n",
      " 'nava naroda' 'vishala' 'purasawalkam' 'santhome' 'jorabagan' 'naranpura'\n",
      " 'magdalla' 'cox town' 'paharganj' 'sector 16 rohini' 'khar east'\n",
      " 'kurla (w)' 'khadia' 'ambegaon' 'bosepukur' 'magob' 'shakurpur'\n",
      " 'nehrunagar' 'chanakyapuri' 'rohini - sector 16' 'tiruvalleeswarar nagar'\n",
      " 'gunrock enclave' 'nagarathpete' 'chudi bazaar' 'koregoan park'\n",
      " 'himayat nagar' 'hakimpet' 'feelkhana' 'golconda fort' 'patel  nagar'\n",
      " 'velly view enclave' 'viman nagar' 'ramnas pura'\n",
      " 'saki naka   andheri east' 'huda colony' 'peerzadiguda' 'rt nagar'\n",
      " 'north dumdum' 'jodhpur tekra' 'sector 29' 'sector 8'\n",
      " 'sri sai tarun enclave' 'ruby area' 'rajarhat' 'mandaveli' 'koyambedu'\n",
      " 'shukrawar peth' 'chintal' 'wallace garden' 'belgachia' 'moosarambagh'\n",
      " 'sima nagar' 'baguiati' 'peravallur' 'pal gam' 'patel nagar'\n",
      " 'marol maroshi road' 'l.p.savani' 'sarkhej road' 'sector v salt lake'\n",
      " 'bandra kurla complex' 'sarvodaya colony' 'matunga wadala'\n",
      " 'somajiguda & khairtabad'\n",
      " 'nehru stadium dark kitchen metro manor sydenhams'\n",
      " 'santoshnagar & saidabad' 'abids & koti' 'near rto pal gam' 'kirti nagar'\n",
      " 'tarnaka  nacharam & malkajigiri' 'santacruz bandra east'\n",
      " 'tarnaka nacharam & malkajigiri' 'nsp' 'a.s. rao nagar & sainikpuri'\n",
      " 'kidderpore' 'juhu' 'nallakunta & vidyanagar' 'ghatkopar vikhroli'\n",
      " 'basaveshwaranagar' 'lakdi ka pul' 'chandkheda' 'sarthana' 'shantinagar'\n",
      " 'paldi & ambawadi' 'chowpati  athwa' 'old wasermenpet' 'battarahalli'\n",
      " 'law college road' 'sion koliwada' 'lower parel worli'\n",
      " 'dr.radhakrishnan salai-mylapore' 'jodhpur cross road' 'vidyanagar'\n",
      " 'kausar baugh nibm road' 'tolichowki hps kids school opposite' 'halsuru'\n",
      " 'l.b nagar' 'vasna' 'borough' 'janakpuri' 'sithaphalmandi'\n",
      " 'srinivas towers' 'dhole patil road' 'appa balwant chowk pune'\n",
      " 'mahalaxmi rd' 'bong chinese ruby area' 'wazirpur industrial area'\n",
      " 'beltala road' 'girish park'\n",
      " 'bldg no15 /402  aniket building  shivaji nagar' 'pitampara'\n",
      " 'rajouri garden extension' 'kakurgachi' 'ekdalia' 'ghatlodia'\n",
      " 'sector -15' 'safal square vesu' 'salt lake - kolkata' 'rani bagh'\n",
      " 'puna patia' 'ultadanga telenga bagan' 'cunningham road'\n",
      " 'mantri sqare mall' 'ra puram' 'matunga east' 'manohar pukur road'\n",
      " 'circus avenue' 'madhavaram - manali' 'central bengalore'\n",
      " 'saki vihar road' 'vv puram' 'prahlad nagar' 'rabindrapally'\n",
      " 'smarpally kestopur' 'r.t. nagar' 'lower parel area' 'vanasthalipuram'\n",
      " 'chinar park' 'ruby park' 'saltlake sector 1' 'secunderabad'\n",
      " 'rohini sector 7' 'church street' 'sanitytestarea' 'picnic garden'\n",
      " 'knk- nungambakam (cds)- chennai' 'kalina ck' 'residency road' 'cg road'\n",
      " 'brigade road' 'south west' 'hyderguda old mla home'\n",
      " 'kankurgachi kolkata' 'gautam buddha nagar' 'andheri west area'\n",
      " 'santacruz east mumbai.' 'vardhman premium mall' 'pcmc'\n",
      " 'lingarajapuram kammanahalli' 'nibm post office road'\n",
      " 'sainik vihar pritampura' 'naroda' 'salunkhe vihar road' 'banjarahills'\n",
      " 'kurla east nehru nagar' 'keshav puram' 'lake market' 'borough - iii'\n",
      " 'new area' 'somwarpeth' 'sarat park' 'dindoli' 'fathima nagar'\n",
      " 'the new sion co-operative housing society' 'chembur colony'\n",
      " 'ghatkopar ck mum' 'rammandir' 'fdl_scruz bandra east' 'gandhi bazaar'\n",
      " 'ramkote' 'sector 15 rohini' 'king koti' 'bibvewadi' 'raviwar peth'\n",
      " 'gudimalkapur' 'kestopur rabindrapally' 'musheerabad' 'somwar peth'\n",
      " 'gaddi annaram' 'balaji nagar' 'krishna nagar colony' 'saligramam'\n",
      " 'sai nagar' 'peeragarhi camp' 'navjivan' 'chilakalguda'\n",
      " 'old mla quarters' 'sector 4 rohini' 'rajamohallah' 'sector 5 rohini'\n",
      " 'vikaspuri' 'ramanthapur' '3rd block jayanagar' 'venkateshwara colony'\n",
      " 'gandhinagar' 'secot 24rohini' 'nallakunta' 'kankaria'\n",
      " 'sindhu bhavan road' 'satara road bibvewadi' 'ganesh peth' 'adajan gam'\n",
      " 'lord sinha rd' 'bhatha' 'athwa gate' 'vip road' 'parvati' 'naktala'\n",
      " 'valasaravakkam' 'girdhar nagar' 'madhupura' 'new textile market'\n",
      " 'majura gate' 'mahim' 'yamuna nagar' 'kalupur' 'bhatar athwa'\n",
      " 'vishal nagar' 'ghodasar' 'yakhutpura' 'salabatpura' 'takara basthi'\n",
      " 'gunti jangaiah nagar' 'jashoda nagar' 'sardar colony' 'katargam'\n",
      " 'moonlight cream sagrampura' 'gidc naroda' 'sanjay nagar' 'pankaj nagar'\n",
      " 'uttran' 'hirabaugh' 'laxmi encleve - katargam' 'krishan vihar' 'nangloi'\n",
      " 'shanti nagar' 'odhav' 'afzal gunj' 'begum bazar' 'old wadaj'\n",
      " 'kadugondanahalli' 'noble nagar tenament' 'ganj peth' 'narol'\n",
      " 'cambridge layout' 'hatkeshwar' 'singanpor' 'yoginagar society'\n",
      " 'bapunagar' 'armane nagar' 'ashok bhai- citylight' 'kg-iii'\n",
      " 'sri durga enclave' 'pocket c-11 sector 5 rohini' 'gomtipur' 'nalgonda'\n",
      " 'mg road' 'tri nagar' 'rani gunj' 'rustampura' 'ghod dod road'\n",
      " 'jayanagar - 3rd block' 'amarpalli' 'anna nagar west'\n",
      " 'kalyan nagar x roads' 'mitul square piplod' 'padma nagar colony'\n",
      " 'rithala rohini' 'rabindra sarovar' 'dhanakawadi' 'kailash plaza'\n",
      " 'mogappair' 'prashant vihar' 'akhbar nagar circle' 'mogapair' 'sri nagar'\n",
      " 'honey park' 'sector -6' 'umra jakat' 'bangur' 'ghod dod road sarelawadi'\n",
      " 'uppal - hyderabad' 'bhavani nagar uppal - hyderabad'\n",
      " 'station road ghatkopar west' 'bhagal' 'jillelaguda' 'sector 3'\n",
      " 'karvenagar' 'sagrampuraathwa' 'sanjay nagar new bel road'\n",
      " 'panjarapole cross road']\n",
      "Data Quality Summary:\n",
      "  Total number of records: 8680\n",
      "  Number of duplicate rows: 0\n",
      "  No columns with missing values.\n",
      "Data Quality Report\n",
      "-----------------------\n",
      "Total number of records: 8680\n",
      "Number of columns: 10\n",
      "Column names: ['ID', 'Area', 'City', 'Restaurant', 'Price', 'Avg ratings', 'Total ratings', 'Food type', 'Address', 'Delivery time']\n",
      "Data types:\n",
      "ID                 int64\n",
      "Area              object\n",
      "City              object\n",
      "Restaurant        object\n",
      "Price            float64\n",
      "Avg ratings      float64\n",
      "Total ratings      int64\n",
      "Food type         object\n",
      "Address           object\n",
      "Delivery time      int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Total missing values: 0\n",
      "Number of duplicate rows: 0\n",
      "Statistics for numerical columns:\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/compat/_optional.py:132\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 328\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead()\u001b[38;5;241m.\u001b[39mto_markdown(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, numalign\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, stralign\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 328\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 320\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    318\u001b[0m check_data_inconsistencies(df)\n\u001b[1;32m    319\u001b[0m get_summary_of_data_quality(df)\n\u001b[0;32m--> 320\u001b[0m \u001b[43mgenerate_data_quality_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m df \u001b[38;5;241m=\u001b[39m advanced_data_imputation(df) \u001b[38;5;66;03m# Impute missing values\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# Print the first 5 rows of the cleaned and imputed DataFrame\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 259\u001b[0m, in \u001b[0;36mgenerate_data_quality_report\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m numerical_cols\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatistics for numerical columns:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumerical_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumalign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstralign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# Distribution of categorical columns\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:2836\u001b[0m, in \u001b[0;36mDataFrame.to_markdown\u001b[0;34m(self, buf, mode, index, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   2834\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtablefmt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2835\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshowindex\u001b[39m\u001b[38;5;124m\"\u001b[39m, index)\n\u001b[0;32m-> 2836\u001b[0m tabulate \u001b[38;5;241m=\u001b[39m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtabulate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2837\u001b[0m result \u001b[38;5;241m=\u001b[39m tabulate\u001b[38;5;241m.\u001b[39mtabulate(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/compat/_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "#suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    \"\"\"\n",
    "    Loads a CSV file into a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The loaded DataFrame, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Dataset successfully loaded from {file_path}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "def check_missing_values(df):\n",
    "    \"\"\"\n",
    "    Checks for missing values in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: A Series containing the count of missing values for each column,\n",
    "                    or None if the input is not a DataFrame.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Error: Input is not a Pandas DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_values = missing_values[missing_values > 0]  # Filter out columns with no missing values\n",
    "    if missing_values.empty:\n",
    "        print(\"No missing values found in the dataset.\")\n",
    "        return None\n",
    "    else:\n",
    "        print(\"Columns with missing values:\")\n",
    "        print(missing_values)\n",
    "        return missing_values\n",
    "\n",
    "def visualize_missing_data(df):\n",
    "    \"\"\"\n",
    "    Visualizes missing data using a heatmap.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Error: Input is not a Pandas DataFrame. Cannot visualize.\")\n",
    "        return\n",
    "\n",
    "    if df.isnull().sum().sum() == 0:\n",
    "        print(\"No missing data to visualize.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "    plt.title('Missing Data Heatmap')\n",
    "    plt.show()\n",
    "\n",
    "def remove_columns_with_many_missing_values(df, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Removes columns with a high percentage of missing values.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    threshold (float): The threshold for the percentage of missing values (0 to 1).\n",
    "                     Columns with missing values above this threshold will be dropped.\n",
    "                     Defaults to 0.5 (50%).\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with columns removed, or None if input is not a DataFrame.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Error: Input is not a Pandas DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    if not 0 <= threshold <= 1:\n",
    "        print(\"Error: Threshold must be between 0 and 1.\")\n",
    "        return df  # Return original DataFrame if threshold is invalid\n",
    "\n",
    "    missing_percentage = df.isnull().sum() / len(df)\n",
    "    columns_to_drop = missing_percentage[missing_percentage > threshold].index\n",
    "    if columns_to_drop.empty:\n",
    "        print(\"No columns found with missing values exceeding the threshold.\")\n",
    "        return df\n",
    "    else:\n",
    "        df_dropped = df.drop(columns=columns_to_drop, axis=1)\n",
    "        print(f\"Dropped columns: {list(columns_to_drop)}\")\n",
    "        print(\"DataFrame shape after dropping columns:\", df_dropped.shape)\n",
    "        return df_dropped\n",
    "\n",
    "def check_duplicate_rows(df):\n",
    "    \"\"\"\n",
    "    Checks for duplicate rows in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing the duplicate rows, or None if input is not a DataFrame.\n",
    "                     Returns an empty DataFrame if no duplicates are found.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Error: Input is not a Pandas DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    duplicate_rows = df[df.duplicated()]\n",
    "    if duplicate_rows.empty:\n",
    "        print(\"No duplicate rows found.\")\n",
    "        return duplicate_rows  # Return empty DataFrame\n",
    "    else:\n",
    "        print(\"Duplicate rows:\")\n",
    "        print(duplicate_rows)\n",
    "        return duplicate_rows\n",
    "\n",
    "def remove_duplicate_rows(df):\n",
    "    \"\"\"\n",
    "    Removes duplicate rows from the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with duplicate rows removed, or None if the input is not a DataFrame.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Error: Input is not a Pandas DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    df_no_duplicates = df.drop_duplicates()\n",
    "    if df_no_duplicates.shape[0] < df.shape[0]:\n",
    "        print(f\"Removed {df.shape[0] - df_no_duplicates.shape[0]} duplicate rows.\")\n",
    "        print(\"DataFrame shape after removing duplicates:\", df_no_duplicates.shape)\n",
    "        return df_no_duplicates\n",
    "    else:\n",
    "        print(\"No duplicate rows to remove.\")\n",
    "        return df_no_duplicates\n",
    "\n",
    "def check_data_inconsistencies(df):\n",
    "    \"\"\"\n",
    "    Checks for inconsistencies in categorical columns.  Specifically, it checks for\n",
    "    leading/trailing whitespace and different capitalization.  It prints the unique\n",
    "    values of each categorical column after stripping whitespace and converting\n",
    "    to lowercase, if any inconsistencies are found.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Error: Input is not a Pandas DataFrame.\")\n",
    "        return\n",
    "\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    if categorical_cols.empty:\n",
    "        print(\"No categorical columns found.\")\n",
    "        return\n",
    "\n",
    "    inconsistencies_found = False\n",
    "    for col in categorical_cols:\n",
    "        # Create a temporary version of the column with cleaned data for comparison\n",
    "        cleaned_values = df[col].astype(str).str.strip().str.lower()\n",
    "        unique_values = cleaned_values.unique()\n",
    "\n",
    "        # Check if the number of unique values in the cleaned version is less than\n",
    "        # the number of unique values in the original column.  If they are different,\n",
    "        # then there were inconsistencies.\n",
    "        if len(unique_values) < len(df[col].unique()):\n",
    "            inconsistencies_found = True\n",
    "            print(f\"Inconsistencies found in column '{col}':\")\n",
    "            print(f\"  Unique values after cleaning: {unique_values}\")\n",
    "\n",
    "    if not inconsistencies_found:\n",
    "        print(\"No inconsistencies found in categorical columns.\")\n",
    "\n",
    "\n",
    "\n",
    "def get_summary_of_data_quality(df):\n",
    "    \"\"\"\n",
    "    Generates a summary of data quality.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Error: Input is not a Pandas DataFrame.\")\n",
    "        return\n",
    "\n",
    "    total_records = len(df)\n",
    "    duplicate_rows = df[df.duplicated()].shape[0]\n",
    "    missing_values = df.isnull().sum()\n",
    "    cols_with_missing_values = missing_values[missing_values > 0].index.tolist()\n",
    "\n",
    "    print(\"Data Quality Summary:\")\n",
    "    print(f\"  Total number of records: {total_records}\")\n",
    "    print(f\"  Number of duplicate rows: {duplicate_rows}\")\n",
    "    if cols_with_missing_values:\n",
    "        print(\"  Columns with missing values:\")\n",
    "        for col in cols_with_missing_values:\n",
    "            print(f\"    {col}: {missing_values[col]} missing values\")\n",
    "    else:\n",
    "        print(\"  No columns with missing values.\")\n",
    "\n",
    "def generate_data_quality_report(df):\n",
    "    \"\"\"\n",
    "    Generates a comprehensive data quality report.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Error: Input is not a Pandas DataFrame.\")\n",
    "        return\n",
    "\n",
    "    print(\"Data Quality Report\")\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    # Basic information\n",
    "    print(f\"Total number of records: {len(df)}\")\n",
    "    print(f\"Number of columns: {df.shape[1]}\")\n",
    "    print(f\"Column names: {df.columns.tolist()}\")\n",
    "    print(f\"Data types:\\n{df.dtypes}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    total_missing = missing_values.sum()\n",
    "    print(f\"Total missing values: {total_missing}\")\n",
    "    if total_missing > 0:\n",
    "        print(\"Missing values per column:\")\n",
    "        print(missing_values[missing_values > 0])\n",
    "        print(\"\\n\")\n",
    "\n",
    "    # Duplicate rows\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "    if duplicate_count > 0:\n",
    "        print(\"First 5 duplicate rows:\")\n",
    "        print(df[df.duplicated()].head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "        print(\"\\n\")\n",
    "\n",
    "    # Statistics for numerical columns\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "    if not numerical_cols.empty:\n",
    "        print(\"Statistics for numerical columns:\")\n",
    "        print(df[numerical_cols].describe().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "        print(\"\\n\")\n",
    "\n",
    "    # Distribution of categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    if not categorical_cols.empty:\n",
    "        print(\"Distribution of categorical columns:\")\n",
    "        for col in categorical_cols:\n",
    "            print(f\"\\nColumn: {col}\")\n",
    "            print(df[col].value_counts().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "def advanced_data_imputation(df):\n",
    "    \"\"\"\n",
    "    Performs advanced data imputation by replacing missing values in numerical\n",
    "    columns with the mean and categorical columns with the mode.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with imputed values, or None if the input is not a DataFrame.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Error: Input is not a Pandas DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    df_imputed = df.copy() # Create a copy to avoid modifying the original DataFrame in place.\n",
    "\n",
    "    for col in df_imputed.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df_imputed[col]):\n",
    "            # Impute numerical columns with the mean\n",
    "            df_imputed[col] = df_imputed[col].fillna(df_imputed[col].mean())\n",
    "            print(f\"Imputed missing values in numerical column '{col}' with the mean.\")\n",
    "        elif pd.api.types.is_categorical_dtype(df_imputed[col]) or pd.api.types.is_object_dtype(df_imputed[col]):\n",
    "            # Impute categorical/object columns with the mode\n",
    "            mode_val = df_imputed[col].mode()[0]  # Get the first mode in case of ties\n",
    "            df_imputed[col] = df_imputed[col].fillna(mode_val)\n",
    "            print(f\"Imputed missing values in categorical/object column '{col}' with the mode: {mode_val}\")\n",
    "\n",
    "    print(\"Advanced data imputation complete.\")\n",
    "    return df_imputed\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the data quality analysis tasks.\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    file_path = 'swiggy.csv'  # Use the correct file path\n",
    "    df = load_dataset(file_path)\n",
    "\n",
    "    if df is None:\n",
    "        return  # Exit if the dataset failed to load\n",
    "\n",
    "    # Perform data quality checks and transformations\n",
    "    check_missing_values(df)\n",
    "    visualize_missing_data(df)\n",
    "    df = remove_columns_with_many_missing_values(df)\n",
    "    check_duplicate_rows(df)\n",
    "    df = remove_duplicate_rows(df)\n",
    "    check_data_inconsistencies(df)\n",
    "    get_summary_of_data_quality(df)\n",
    "    generate_data_quality_report(df)\n",
    "    df = advanced_data_imputation(df) # Impute missing values\n",
    "\n",
    "    # Print the first 5 rows of the cleaned and imputed DataFrame\n",
    "    print(\"\\nFirst 5 rows of the cleaned and imputed DataFrame:\")\n",
    "    print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
