{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Load a Dataset & Check Missing Values\n",
    "\n",
    "# Task 1: Titanic Dataset\n",
    "# - Load the dataset using Pandas.\n",
    "# - Check for missing values in the 'Age' column.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Part 2: Identify Duplicates & Inconsistencies\n",
    "\n",
    "# Task 2: Duplicate Rows in Titanic Dataset\n",
    "# - Identify any duplicate rows in the dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Part 3: Generate a Data Quality Report\n",
    "\n",
    "# Task 3: Titanic Dataset Overview\n",
    "# - Create a simple report of missing values, duplicates, and some basic statistics for the Titanic dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset from: titanic.csv\n",
      "\n",
      "--- Data Quality Report for Titanic Dataset ---\n",
      "\n",
      "Missing Values in 'Age' column:\n",
      "177\n",
      "\n",
      "Duplicate Rows:\n",
      "0\n",
      "\n",
      "Basic Statistics:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "\n",
      "First 5 rows of the dataframe:\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/compat/_optional.py:132\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 68\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df  \u001b[38;5;66;03m# Return the DataFrame for further use if needed.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# You can specify the file path if it's not the default \"titanic.csv\"\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     titanic_df \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_titanic_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Uses default\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# titanic_df = analyze_titanic_data(\"path/to/your/titanic.csv\")\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m titanic_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 62\u001b[0m, in \u001b[0;36manalyze_titanic_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Print the first few rows of the dataframe\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFirst 5 rows of the dataframe:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumalign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstralign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:2836\u001b[0m, in \u001b[0;36mDataFrame.to_markdown\u001b[0;34m(self, buf, mode, index, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   2834\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtablefmt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2835\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshowindex\u001b[39m\u001b[38;5;124m\"\u001b[39m, index)\n\u001b[0;32m-> 2836\u001b[0m tabulate \u001b[38;5;241m=\u001b[39m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtabulate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2837\u001b[0m result \u001b[38;5;241m=\u001b[39m tabulate\u001b[38;5;241m.\u001b[39mtabulate(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/compat/_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_titanic_data(file_path=\"titanic.csv\"):\n",
    "    \"\"\"\n",
    "    Analyzes the Titanic dataset for missing values, duplicates,\n",
    "    and generates a basic data quality report.\n",
    "\n",
    "    Args:\n",
    "        file_path (str, optional): Path to the Titanic dataset CSV file.\n",
    "            Defaults to \"titanic.csv\".  If the file is not found,\n",
    "            it will attempt to use a placeholder DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Returns the original dataframe. Prints a data quality report\n",
    "        to the console.  Returns None if a critical error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Task 1: Load the dataset using Pandas\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Loaded dataset from: {file_path}\")  # Inform about the file loaded\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}.  Using placeholder data.\")\n",
    "        # Create a placeholder DataFrame with the specified columns\n",
    "        df = pd.DataFrame({\n",
    "            'PassengerId': [1, 2, 3, 4, 5],\n",
    "            'Survived': [0, 1, 1, 0, 1],\n",
    "            'Pclass': [3, 1, 3, 1, 3],\n",
    "            'Name': ['Owen Harris Braund', 'Florence Briggs Thayer', 'John Edward Brown', 'William Henry Allen', 'James Moran'],\n",
    "            'Sex': ['male', 'female', 'female', 'male', 'male'],\n",
    "            'Age': [22.0, 38.0, 26.0, 35.0, None],\n",
    "            'SibSp': [1, 1, 0, 0, 0],\n",
    "            'Parch': [0, 0, 0, 0, 0],\n",
    "            'Ticket': ['A/5 21151', 'PC 17599', 'STON/O2. 3101282', '373450', '330877'],\n",
    "            'Fare': [7.25, 71.2833, 7.925, 8.05, 8.4583],\n",
    "            'Cabin': [None, 'C85', None, None, None],\n",
    "            'Embarked': ['S', 'C', 'S', 'S', 'Q']\n",
    "        })\n",
    "\n",
    "    # Check if the DataFrame is empty\n",
    "    if df.empty:\n",
    "        print(\"Error: The DataFrame is empty.  Please check the data source.\")\n",
    "        return None\n",
    "\n",
    "    # --- Data Quality Analysis ---\n",
    "    print(\"\\n--- Data Quality Report for Titanic Dataset ---\")\n",
    "\n",
    "    # Task 1: Check for missing values in the 'Age' column.\n",
    "    print(\"\\nMissing Values in 'Age' column:\")\n",
    "    print(df['Age'].isnull().sum())\n",
    "\n",
    "    # Task 2: Identify any duplicate rows in the dataset.\n",
    "    print(\"\\nDuplicate Rows:\")\n",
    "    duplicate_rows = df.duplicated().sum()\n",
    "    print(duplicate_rows)\n",
    "\n",
    "    # Task 3: Generate a basic statistics for the Titanic dataset.\n",
    "    print(\"\\nBasic Statistics:\")\n",
    "    print(df.describe())\n",
    "\n",
    "    # Print the first few rows of the dataframe\n",
    "    print(\"\\nFirst 5 rows of the dataframe:\")\n",
    "    print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "    return df  # Return the DataFrame for further use if needed.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can specify the file path if it's not the default \"titanic.csv\"\n",
    "    titanic_df = analyze_titanic_data() # Uses default\n",
    "    # titanic_df = analyze_titanic_data(\"path/to/your/titanic.csv\")\n",
    "    if titanic_df is not None:\n",
    "        print(\"\\nAnalysis Complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
