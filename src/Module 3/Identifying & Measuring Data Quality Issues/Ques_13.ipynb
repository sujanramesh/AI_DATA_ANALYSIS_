{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Quality Metrics & Scoring Examples\n",
    "\n",
    "# Task 1:\n",
    "# Assign scores to a customer dataset based on completeness, uniqueness, and consistency.\n",
    "# Analyze the overall data quality score and identify areas for improvement.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 2:\n",
    "# Evaluate a dataset for an online shop using metrics such as accuracy, timeliness, and\n",
    "# integrity. Calculate the data quality score and provide improvement suggestions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 3:\n",
    "# Perform a data quality assessment on a financial dataset, scoring it based on validity,\n",
    "# precision, and accessibility. Review the results and propose corrective actions.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Quality Metrics & Scoring Examples ---\n",
      "\n",
      "--- Task 1: Customer Dataset Quality Scoring ---\n",
      "Completeness (Name): 85.71%\n",
      "Completeness (Email): 85.71%\n",
      "Completeness (Phone): 85.71%\n",
      "Uniqueness (CustomerID): 85.71%\n",
      "Uniqueness (Email): 71.43%\n",
      "Uniqueness (Phone): 71.43%\n",
      "Consistency (City): 42.86%\n",
      "\n",
      "Overall Data Quality Score (Task 1): 75.51%\n",
      "\n",
      "Areas for Improvement (Task 1):\n",
      "- Missing values in 'Name' column.\n",
      "- Missing values in 'Email' column.\n",
      "- Missing values in 'Phone' column.\n",
      "- Duplicate values in 'CustomerID' column.\n",
      "- Duplicate values in 'Email' column.\n",
      "- Duplicate values in 'Phone' column.\n",
      "- Inconsistencies in 'City' values (if applicable with more varied data).\n",
      "\n",
      "--- Task 2: Online Shop Dataset Quality Scoring ---\n",
      "Accuracy (Stock Status): 100.00%\n",
      "Timeliness (Delivery): 100.00%\n",
      "Integrity (OrderID Uniqueness): 100.00%\n",
      "\n",
      "Overall Data Quality Score (Task 2): 100.00%\n",
      "\n",
      "Improvement Suggestions (Task 2):\n",
      "\n",
      "--- Task 3: Financial Dataset Quality Scoring ---\n",
      "Validity (Currency): 100.00%\n",
      "Validity (TransactionDate): 100.00%\n",
      "Precision (Amount): 100.00%\n",
      "Precision (PrecisionCheck): 100.00%\n",
      "Accessibility (Overall Completeness): 100.00%\n",
      "\n",
      "Overall Data Quality Score (Task 3): 100.00%\n",
      "\n",
      "Proposed Corrective Actions (Task 3):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16894/546595972.py:145: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  is_valid = df[column].apply(lambda x: any(pd.to_datetime(x, format=fmt, errors='ignore') is not pd.NaT for fmt in valid_formats))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- Data Quality Metrics & Scoring Examples ---\")\n",
    "\n",
    "# --- Task 1: Customer Dataset ---\n",
    "print(\"\\n--- Task 1: Customer Dataset Quality Scoring ---\")\n",
    "\n",
    "customer_data = pd.DataFrame({\n",
    "    'CustomerID': [1, 2, 3, 4, 5, 1, 7],\n",
    "    'Name': ['Alice', 'Bob', None, 'David', 'Eve', 'Alice', 'Frank'],\n",
    "    'Email': ['alice@example.com', 'bob@sample.org', 'charlie@test.net', 'david@work.net', None, 'alice@example.com', 'frank@home.com'],\n",
    "    'Phone': ['123-456-7890', '987-654-3210', '555-123-4567', None, '111-222-3333', '123-456-7890', '444-555-6666'],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Seattle', 'New York', 'Austin']\n",
    "})\n",
    "\n",
    "def score_completeness(df, column):\n",
    "    total = len(df)\n",
    "    not_null = df[column].count()\n",
    "    return (not_null / total) * 100\n",
    "\n",
    "def score_uniqueness(df, column):\n",
    "    total = len(df)\n",
    "    unique = df[column].nunique()\n",
    "    return (unique / total) * 100\n",
    "\n",
    "def score_consistency(df, column):\n",
    "    # Simple example for consistency in categorical data (more complex checks needed for other types)\n",
    "    if df[column].dtype == 'object':\n",
    "        value_counts = df[column].value_counts(dropna=False)\n",
    "        most_frequent_count = value_counts.max()\n",
    "        total = len(df)\n",
    "        return (most_frequent_count / total) * 100\n",
    "    return 100 # Assume consistent if not object for this simple example\n",
    "\n",
    "completeness_name = score_completeness(customer_data, 'Name')\n",
    "completeness_email = score_completeness(customer_data, 'Email')\n",
    "completeness_phone = score_completeness(customer_data, 'Phone')\n",
    "\n",
    "uniqueness_customer_id = score_uniqueness(customer_data, 'CustomerID')\n",
    "uniqueness_email = score_uniqueness(customer_data, 'Email')\n",
    "uniqueness_phone = score_uniqueness(customer_data, 'Phone')\n",
    "\n",
    "consistency_city = score_consistency(customer_data, 'City')\n",
    "\n",
    "overall_quality_task1 = np.mean([\n",
    "    completeness_name, completeness_email, completeness_phone,\n",
    "    uniqueness_customer_id, uniqueness_email, uniqueness_phone,\n",
    "    consistency_city\n",
    "])\n",
    "\n",
    "print(f\"Completeness (Name): {completeness_name:.2f}%\")\n",
    "print(f\"Completeness (Email): {completeness_email:.2f}%\")\n",
    "print(f\"Completeness (Phone): {completeness_phone:.2f}%\")\n",
    "print(f\"Uniqueness (CustomerID): {uniqueness_customer_id:.2f}%\")\n",
    "print(f\"Uniqueness (Email): {uniqueness_email:.2f}%\")\n",
    "print(f\"Uniqueness (Phone): {uniqueness_phone:.2f}%\")\n",
    "print(f\"Consistency (City): {consistency_city:.2f}%\")\n",
    "print(f\"\\nOverall Data Quality Score (Task 1): {overall_quality_task1:.2f}%\")\n",
    "print(\"\\nAreas for Improvement (Task 1):\")\n",
    "if completeness_name < 100:\n",
    "    print(\"- Missing values in 'Name' column.\")\n",
    "if completeness_email < 100:\n",
    "    print(\"- Missing values in 'Email' column.\")\n",
    "if completeness_phone < 100:\n",
    "    print(\"- Missing values in 'Phone' column.\")\n",
    "if uniqueness_customer_id < 100:\n",
    "    print(\"- Duplicate values in 'CustomerID' column.\")\n",
    "if uniqueness_email < 100:\n",
    "    print(\"- Duplicate values in 'Email' column.\")\n",
    "if uniqueness_phone < 100:\n",
    "    print(\"- Duplicate values in 'Phone' column.\")\n",
    "if consistency_city < 100:\n",
    "    print(\"- Inconsistencies in 'City' values (if applicable with more varied data).\")\n",
    "\n",
    "# --- Task 2: Online Shop Dataset ---\n",
    "print(\"\\n--- Task 2: Online Shop Dataset Quality Scoring ---\")\n",
    "\n",
    "shop_data = pd.DataFrame({\n",
    "    'OrderID': [1, 2, 3, 4, 5],\n",
    "    'ProductID': ['A101', 'B202', 'C303', 'A101', 'D404'],\n",
    "    'ProductName': ['Laptop', 'Mouse', 'Keyboard', 'Laptop', 'Monitor'],\n",
    "    'OrderDate': ['2023-01-15', '2023-01-20', '2023-02-10', '2023-01-15', '2023-03-01'],\n",
    "    'DeliveryDate': ['2023-01-18', '2023-01-22', '2023-02-15', '2023-01-18', '2023-03-05'],\n",
    "    'Price': [1200.00, 25.00, 75.00, 1200, 300.00], # Inconsistent data type for Price in one row\n",
    "    'StockStatus': ['In Stock', 'Out of Stock', 'In Stock', 'In Stock', 'Low Stock']\n",
    "})\n",
    "\n",
    "def score_accuracy(df, column, expected_values=None):\n",
    "    # Simple example for categorical accuracy\n",
    "    if expected_values:\n",
    "        valid_count = df[df[column].isin(expected_values)].count()[column]\n",
    "        total = len(df)\n",
    "        return (valid_count / total) * 100\n",
    "    return 100 # Need specific validation rules for numeric/date\n",
    "\n",
    "def score_timeliness(df, order_date_col, delivery_date_col):\n",
    "    df_copy = df.dropna(subset=[order_date_col, delivery_date_col]).copy()\n",
    "    try:\n",
    "        df_copy['OrderDate'] = pd.to_datetime(df_copy[order_date_col])\n",
    "        df_copy['DeliveryDate'] = pd.to_datetime(df_copy[delivery_date_col])\n",
    "        on_time_deliveries = len(df_copy[df_copy['DeliveryDate'] >= df_copy['OrderDate']])\n",
    "        total_deliveries = len(df_copy)\n",
    "        return (on_time_deliveries / total_deliveries) * 100 if total_deliveries > 0 else 100\n",
    "    except ValueError:\n",
    "        return 0 # Error in date conversion\n",
    "\n",
    "def score_integrity(df, unique_key_col):\n",
    "    return score_uniqueness(df, unique_key_col)\n",
    "\n",
    "accuracy_stock_status = score_accuracy(shop_data, 'StockStatus', expected_values=['In Stock', 'Out of Stock', 'Low Stock'])\n",
    "timeliness_delivery = score_timeliness(shop_data, 'OrderDate', 'DeliveryDate')\n",
    "integrity_order_id = score_integrity(shop_data, 'OrderID')\n",
    "\n",
    "overall_quality_task2 = np.mean([accuracy_stock_status, timeliness_delivery, integrity_order_id])\n",
    "\n",
    "print(f\"Accuracy (Stock Status): {accuracy_stock_status:.2f}%\")\n",
    "print(f\"Timeliness (Delivery): {timeliness_delivery:.2f}%\")\n",
    "print(f\"Integrity (OrderID Uniqueness): {integrity_order_id:.2f}%\")\n",
    "print(f\"\\nOverall Data Quality Score (Task 2): {overall_quality_task2:.2f}%\")\n",
    "print(\"\\nImprovement Suggestions (Task 2):\")\n",
    "if accuracy_stock_status < 100:\n",
    "    print(\"- Validate 'StockStatus' values against a predefined list.\")\n",
    "if timeliness_delivery < 100:\n",
    "    print(\"- Investigate orders with delivery dates before order dates (potential errors).\")\n",
    "if integrity_order_id < 100:\n",
    "    print(\"- Ensure 'OrderID' values are unique.\")\n",
    "if shop_data['Price'].dtype != 'float64':\n",
    "    print(\"- Ensure consistent data type for 'Price' column (e.g., numeric).\")\n",
    "\n",
    "# --- Task 3: Financial Dataset ---\n",
    "print(\"\\n--- Task 3: Financial Dataset Quality Scoring ---\")\n",
    "\n",
    "financial_data = pd.DataFrame({\n",
    "    'TransactionID': [1001, 1002, 1003, 1004, 1005],\n",
    "    'AccountID': ['ACC123', 'ACC456', 'INV789', 'ACC123', 'LOAN01'],\n",
    "    'Amount': [100.50, 200.75, '300', 400.00, 500.25], # Non-numeric value\n",
    "    'TransactionDate': ['2024-01-01', '2024-01-05', '2024-01-10', '2024-01-01', '2024-01-15'],\n",
    "    'Currency': ['USD', 'EUR', 'USD', 'USD', 'GBP'],\n",
    "    'PrecisionCheck': [1.000, 2.00, 3, 4.0000, 5.00] # Varying precision\n",
    "})\n",
    "\n",
    "def score_validity(df, column, valid_formats=None, valid_values=None):\n",
    "    if valid_formats:\n",
    "        is_valid = df[column].apply(lambda x: any(pd.to_datetime(x, format=fmt, errors='ignore') is not pd.NaT for fmt in valid_formats))\n",
    "        return (is_valid.sum() / len(df)) * 100\n",
    "    elif valid_values:\n",
    "        valid_count = df[df[column].isin(valid_values)].count()[column]\n",
    "        return (valid_count / len(df)) * 100\n",
    "    return 100\n",
    "\n",
    "def score_precision(df, column, decimal_places=2):\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        max_decimals = df[column].astype(str).str.split('.').str[-1].str.len().max()\n",
    "        if pd.isna(max_decimals):\n",
    "            return 100\n",
    "        return (max(0, decimal_places - max_decimals + 1) / (max_decimals + 1)) * 100\n",
    "    return 100\n",
    "\n",
    "def score_accessibility(df):\n",
    "    # Simple check: percentage of non-null values across all columns (proxy for accessibility)\n",
    "    total_cells = df.size\n",
    "    non_null_cells = df.count().sum()\n",
    "    return (non_null_cells / total_cells) * 100\n",
    "\n",
    "validity_currency = score_validity(financial_data, 'Currency', valid_values=['USD', 'EUR', 'GBP'])\n",
    "validity_date = score_validity(financial_data, 'TransactionDate', valid_formats=['%Y-%m-%d'])\n",
    "precision_amount = score_precision(financial_data, 'Amount', decimal_places=2)\n",
    "precision_check = score_precision(financial_data, 'PrecisionCheck', decimal_places=2)\n",
    "accessibility_data = score_accessibility(financial_data)\n",
    "\n",
    "overall_quality_task3 = np.mean([validity_currency, validity_date, precision_amount, precision_check, accessibility_data])\n",
    "\n",
    "print(f\"Validity (Currency): {validity_currency:.2f}%\")\n",
    "print(f\"Validity (TransactionDate): {validity_date:.2f}%\")\n",
    "print(f\"Precision (Amount): {precision_amount:.2f}%\")\n",
    "print(f\"Precision (PrecisionCheck): {precision_check:.2f}%\")\n",
    "print(f\"Accessibility (Overall Completeness): {accessibility_data:.2f}%\")\n",
    "print(f\"\\nOverall Data Quality Score (Task 3): {overall_quality_task3:.2f}%\")\n",
    "print(\"\\nProposed Corrective Actions (Task 3):\")\n",
    "if validity_currency < 100:\n",
    "    print(\"- Standardize 'Currency' values to a defined set.\")\n",
    "if validity_date < 100:\n",
    "    print(\"- Ensure all 'TransactionDate' values adhere to the 'YYYY-MM-DD' format.\")\n",
    "if precision_amount < 100:\n",
    "    print(\"- Convert 'Amount' column to a numeric type and enforce consistent precision (e.g., 2 decimal places).\")\n",
    "if precision_check < 100:\n",
    "    print(\"- Standardize the precision of values in the 'PrecisionCheck' column to 2 decimal places.\")\n",
    "if accessibility_data < 100:\n",
    "    print(\"- Investigate and handle any missing values across the dataset.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
