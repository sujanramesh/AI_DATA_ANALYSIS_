{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 4: Data Quality Automation Tools\n",
    "\n",
    "# Task A: Using Great Expectations\n",
    "\n",
    "# 19. Setting Up Expectations:\n",
    "# - Install Great Expectations and set up a basic expectation suite.\n",
    "# - Validate a dataset and list unmet expectations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 20. Testing for Expectation:\n",
    "# - Create expectations such as “column values must fall within a certain range.”\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 21. Generating Data Docs:\n",
    "# - Automatically generate data quality documentation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task B: Using DQ Labs\n",
    "\n",
    "# 22. Tool Setup and Configuration:\n",
    "# - Download and configure DQ Labs on your local environment.\n",
    "# - Create a new data quality project.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 23. Data Analysis Automation:\n",
    "# - Apply DQ Labs for automating data profiling and quality checks.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 24. Quality Rule Creation:\n",
    "# - Create quality rules for detecting and handling duplicates or enforcing standards.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Unmet Expectations ---\n",
      "Expectation: column_values_not_be_null - Column: col1 - Details: Number of null values: 1\n",
      "Expectation: column_values_in_set - Column: col2 - Details: Invalid values: ['E']\n",
      "Expectation: column_values_between - Column: col3 - Details: Out of range values: [60]\n",
      "\n",
      "--- Simple Data Docs Generated ---\n",
      "Report saved to: data_quality_report.txt\n",
      "\n",
      "--- Data Profile ---\n",
      "Column: col1\n",
      "  data_type: float64\n",
      "  non_null_count: 5\n",
      "  null_count: 1\n",
      "  unique_count: 5\n",
      "  min: 1.0\n",
      "  max: 5.0\n",
      "  top_value: 1.0\n",
      "  top_value_count: 1\n",
      "--------------------\n",
      "Column: col2\n",
      "  data_type: object\n",
      "  non_null_count: 6\n",
      "  null_count: 0\n",
      "  unique_count: 4\n",
      "  min: None\n",
      "  max: None\n",
      "  top_value: A\n",
      "  top_value_count: 3\n",
      "--------------------\n",
      "Column: col3\n",
      "  data_type: int64\n",
      "  non_null_count: 6\n",
      "  null_count: 0\n",
      "  unique_count: 6\n",
      "  min: 10\n",
      "  max: 60\n",
      "  top_value: 10\n",
      "  top_value_count: 1\n",
      "--------------------\n",
      "Column: email\n",
      "  data_type: object\n",
      "  non_null_count: 5\n",
      "  null_count: 1\n",
      "  unique_count: 4\n",
      "  min: None\n",
      "  max: None\n",
      "  top_value: test@example.com\n",
      "  top_value_count: 2\n",
      "--------------------\n",
      "\n",
      "--- Duplicate Check ---\n",
      "Rule: check_duplicates\n",
      "Columns: ['col1', 'col2']\n",
      "Success: True\n",
      "Details: Number of duplicate rows (considering ['col1', 'col2']): 0\n",
      "\n",
      "--- Value Set Enforcement ---\n",
      "Rule: enforce_value_set\n",
      "Column: col2\n",
      "Success: False\n",
      "Details: Violating values: ['E']\n"
     ]
    }
   ],
   "source": [
    "# Task A: Simulating Great Expectations with Python\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def check_expectation_not_null(df, column):\n",
    "    \"\"\"Checks if all values in a column are not null.\"\"\"\n",
    "    null_values = df[df[column].isnull()]\n",
    "    success = null_values.empty\n",
    "    details = f\"Number of null values: {len(null_values)}\"\n",
    "    return {\"success\": success, \"details\": details, \"expectation\": \"column_values_not_be_null\", \"column\": column}\n",
    "\n",
    "def check_expectation_in_set(df, column, value_set):\n",
    "    \"\"\"Checks if all values in a column are within a specified set.\"\"\"\n",
    "    invalid_values = df[~df[column].isin(value_set)]\n",
    "    success = invalid_values.empty\n",
    "    details = f\"Invalid values: {invalid_values[column].unique().tolist()}\"\n",
    "    return {\"success\": success, \"details\": details, \"expectation\": \"column_values_in_set\", \"column\": column, \"value_set\": value_set}\n",
    "\n",
    "def check_expectation_between(df, column, min_value, max_value):\n",
    "    \"\"\"Checks if all values in a column are within a specified range.\"\"\"\n",
    "    out_of_range = df[(df[column] < min_value) | (df[column] > max_value)]\n",
    "    success = out_of_range.empty\n",
    "    details = f\"Out of range values: {out_of_range[column].unique().tolist()}\"\n",
    "    return {\"success\": success, \"details\": details, \"expectation\": \"column_values_between\", \"column\": column, \"min_value\": min_value, \"max_value\": max_value}\n",
    "\n",
    "def validate_data(df, expectations):\n",
    "    \"\"\"Validates a DataFrame against a list of expectations.\"\"\"\n",
    "    results = []\n",
    "    for expectation in expectations:\n",
    "        expectation_type = expectation['type']\n",
    "        kwargs = expectation['kwargs']\n",
    "        if expectation_type == \"column_values_not_be_null\":\n",
    "            results.append(check_expectation_not_null(df, **kwargs))\n",
    "        elif expectation_type == \"column_values_in_set\":\n",
    "            results.append(check_expectation_in_set(df, **kwargs))\n",
    "        elif expectation_type == \"column_values_between\":\n",
    "            results.append(check_expectation_between(df, **kwargs))\n",
    "        else:\n",
    "            results.append({\"success\": False, \"details\": f\"Unknown expectation type: {expectation_type}\", \"expectation\": expectation_type})\n",
    "    return results\n",
    "\n",
    "def list_unmet_expectations(validation_results):\n",
    "    \"\"\"Lists the expectations that were not met.\"\"\"\n",
    "    unmet = [result for result in validation_results if not result['success']]\n",
    "    if unmet:\n",
    "        print(\"\\n--- Unmet Expectations ---\")\n",
    "        for result in unmet:\n",
    "            print(f\"Expectation: {result['expectation']} - Column: {result.get('column', 'N/A')} - Details: {result['details']}\")\n",
    "    else:\n",
    "        print(\"\\n--- All Expectations Met ---\")\n",
    "\n",
    "def generate_data_docs_simple(validation_results, output_file=\"data_quality_report.txt\"):\n",
    "    \"\"\"Generates a simple text-based data quality report.\"\"\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(\"--- Data Quality Report ---\\n\\n\")\n",
    "        for result in validation_results:\n",
    "            f.write(f\"Expectation: {result['expectation']}\\n\")\n",
    "            f.write(f\"Column: {result.get('column', 'N/A')}\\n\")\n",
    "            f.write(f\"Success: {result['success']}\\n\")\n",
    "            f.write(f\"Details: {result['details']}\\n\")\n",
    "            f.write(\"-\" * 30 + \"\\n\")\n",
    "    print(f\"\\n--- Simple Data Docs Generated ---\")\n",
    "    print(f\"Report saved to: {output_file}\")\n",
    "\n",
    "# Task B: Simulating DQ Labs with Python\n",
    "\n",
    "def analyze_data_profile(df):\n",
    "    \"\"\"Simulates basic data profiling.\"\"\"\n",
    "    profile = {}\n",
    "    for col in df.columns:\n",
    "        profile[col] = {\n",
    "            \"data_type\": df[col].dtype,\n",
    "            \"non_null_count\": df[col].count(),\n",
    "            \"null_count\": df[col].isnull().sum(),\n",
    "            \"unique_count\": df[col].nunique(),\n",
    "            \"min\": df[col].min() if pd.api.types.is_numeric_dtype(df[col]) else None,\n",
    "            \"max\": df[col].max() if pd.api.types.is_numeric_dtype(df[col]) else None,\n",
    "            \"top_value\": df[col].mode().iloc[0] if not df[col].empty else None,\n",
    "            \"top_value_count\": df[col].value_counts().iloc[0] if not df[col].empty else 0\n",
    "        }\n",
    "    print(\"\\n--- Data Profile ---\")\n",
    "    for col, stats in profile.items():\n",
    "        print(f\"Column: {col}\")\n",
    "        for key, value in stats.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print(\"-\" * 20)\n",
    "    return profile\n",
    "\n",
    "def check_duplicates(df, columns=None):\n",
    "    \"\"\"Checks for duplicate rows based on specified columns.\"\"\"\n",
    "    if columns:\n",
    "        duplicates = df[df.duplicated(subset=columns, keep=False)]\n",
    "        duplicate_count = duplicates.shape[0] // df.duplicated(subset=columns).sum() if df.duplicated(subset=columns).sum() > 0 else 0\n",
    "        details = f\"Number of duplicate rows (considering {columns}): {duplicates.shape[0]}\"\n",
    "    else:\n",
    "        duplicates = df[df.duplicated(keep=False)]\n",
    "        duplicate_count = duplicates.shape[0] // df.duplicated().sum() if df.duplicated().sum() > 0 else 0\n",
    "        details = f\"Number of duplicate rows (considering all columns): {duplicates.shape[0]}\"\n",
    "    success = duplicates.empty\n",
    "    return {\"success\": success, \"details\": details, \"rule\": \"check_duplicates\", \"columns\": columns, \"duplicate_count\": duplicate_count}\n",
    "\n",
    "def enforce_value_set(df, column, allowed_values):\n",
    "    \"\"\"Checks if all values in a column are within a specified set and flags violations.\"\"\"\n",
    "    violations = df[~df[column].isin(allowed_values)]\n",
    "    success = violations.empty\n",
    "    details = f\"Violating values: {violations[column].unique().tolist()}\"\n",
    "    return {\"success\": success, \"details\": details, \"rule\": \"enforce_value_set\", \"column\": column, \"allowed_values\": allowed_values, \"violation_count\": len(violations)}\n",
    "\n",
    "# Example Usage:\n",
    "data = {'col1': [1, 2, 3, 4, 5, None],\n",
    "        'col2': ['A', 'B', 'C', 'A', 'E', 'A'],\n",
    "        'col3': [10, 20, 30, 60, 50, 15],\n",
    "        'email': ['test@example.com', 'invalid', 'another@domain.net', 'test@example.com', None, 'third@example.com']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Task A: Using Simulated Great Expectations\n",
    "expectations_suite = [\n",
    "    {\"type\": \"column_values_not_be_null\", \"kwargs\": {\"column\": \"col1\"}},\n",
    "    {\"type\": \"column_values_in_set\", \"kwargs\": {\"column\": \"col2\", \"value_set\": [\"A\", \"B\", \"C\", \"D\"]}},\n",
    "    {\"type\": \"column_values_between\", \"kwargs\": {\"column\": \"col3\", \"min_value\": 5, \"max_value\": 55}}\n",
    "]\n",
    "\n",
    "validation_results = validate_data(df, expectations_suite)\n",
    "list_unmet_expectations(validation_results)\n",
    "generate_data_docs_simple(validation_results)\n",
    "\n",
    "# Task B: Simulating DQ Labs\n",
    "analyze_data_profile(df)\n",
    "\n",
    "duplicate_check_result = check_duplicates(df, columns=['col1', 'col2'])\n",
    "print(\"\\n--- Duplicate Check ---\")\n",
    "print(f\"Rule: {duplicate_check_result['rule']}\")\n",
    "print(f\"Columns: {duplicate_check_result.get('columns', 'All')}\")\n",
    "print(f\"Success: {duplicate_check_result['success']}\")\n",
    "print(f\"Details: {duplicate_check_result['details']}\")\n",
    "\n",
    "value_set_enforcement_result = enforce_value_set(df, 'col2', ['A', 'B', 'C', 'D'])\n",
    "print(\"\\n--- Value Set Enforcement ---\")\n",
    "print(f\"Rule: {value_set_enforcement_result['rule']}\")\n",
    "print(f\"Column: {value_set_enforcement_result['column']}\")\n",
    "print(f\"Success: {value_set_enforcement_result['success']}\")\n",
    "print(f\"Details: {value_set_enforcement_result['details']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
