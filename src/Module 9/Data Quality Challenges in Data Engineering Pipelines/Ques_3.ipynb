{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata Management for Data Quality\n",
    "**Description**: Store and use metadata to manage data quality in a pipeline.\n",
    "\n",
    "**Steps**:\n",
    "1. Load metadata\n",
    "2. Load data\n",
    "3. Use metadata to validate data quality\n",
    "4. Show valid data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Metadata Loaded.\n",
      "{\n",
      "  \"schema\": {\n",
      "    \"product_id\": {\n",
      "      \"type\": \"int\",\n",
      "      \"nullable\": false\n",
      "    },\n",
      "    \"product_name\": {\n",
      "      \"type\": \"str\",\n",
      "      \"nullable\": false\n",
      "    },\n",
      "    \"price\": {\n",
      "      \"type\": \"float\",\n",
      "      \"nullable\": false,\n",
      "      \"min_value\": 0.01,\n",
      "      \"max_value\": 1000.0\n",
      "    },\n",
      "    \"stock_quantity\": {\n",
      "      \"type\": \"int\",\n",
      "      \"nullable\": false,\n",
      "      \"min_value\": 0\n",
      "    },\n",
      "    \"category\": {\n",
      "      \"type\": \"str\",\n",
      "      \"nullable\": true,\n",
      "      \"allowed_values\": [\n",
      "        \"Electronics\",\n",
      "        \"Books\",\n",
      "        \"Clothing\",\n",
      "        \"Home Goods\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"quality_checks\": {\n",
      "    \"price_range\": \"price >= min_value and price <= max_value\",\n",
      "    \"stock_positive\": \"stock_quantity >= min_value\",\n",
      "    \"category_valid\": \"category in allowed_values or category is None\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Step 2: Data Loaded.\n",
      "\n",
      "Original DataFrame:\n",
      "   product_id      product_name    price  stock_quantity     category\n",
      "0         101            Laptop  1200.50            50.0  Electronics\n",
      "1         102             Novel    15.99           200.0        Books\n",
      "2         103           T-Shirt    25.00           150.0     Clothing\n",
      "3         104      Coffee Maker    99.99            30.0   Home Goods\n",
      "4         105     Invalid Price    -5.00            10.0  Electronics\n",
      "5         106        Zero Stock    50.00             0.0        Books\n",
      "6         107  Invalid Category   100.00            20.0      Gadgets\n",
      "7         108     Missing Stock   200.00             NaN  Electronics\n",
      "8         109     Missing Price      NaN             5.0     Clothing\n",
      "9         110     Valid Product    75.00           100.0  Electronics\n",
      "\n",
      "Original DataFrame shape: (10, 5)\n",
      "\n",
      "Step 3: Validating Data Quality using Metadata...\n",
      "\n",
      "Data Quality Validation Summary:\n",
      "The following data quality issues were found:\n",
      "- Null values in non-nullable column 'price'\n",
      "- Out of range values in 'price': [1200.5, -5.0]\n",
      "- Type mismatch in 'stock_quantity': [50.0, 200.0, 150.0, 30.0, 10.0, 0.0, 20.0, 5.0, 100.0]\n",
      "- Null values in non-nullable column 'stock_quantity'\n",
      "- Invalid category in 'category': ['Gadgets']\n",
      "\n",
      "Step 4: Valid Data (rows that passed all quality checks):\n",
      "No valid data found after applying quality checks.\n",
      "\n",
      "Invalid Data (rows that failed at least one quality check):\n",
      "   product_id      product_name    price  stock_quantity     category\n",
      "0         101            Laptop  1200.50            50.0  Electronics\n",
      "1         102             Novel    15.99           200.0        Books\n",
      "2         103           T-Shirt    25.00           150.0     Clothing\n",
      "3         104      Coffee Maker    99.99            30.0   Home Goods\n",
      "4         105     Invalid Price    -5.00            10.0  Electronics\n",
      "5         106        Zero Stock    50.00             0.0        Books\n",
      "6         107  Invalid Category   100.00            20.0      Gadgets\n",
      "7         108     Missing Stock   200.00             NaN  Electronics\n",
      "8         109     Missing Price      NaN             5.0     Clothing\n",
      "9         110     Valid Product    75.00           100.0  Electronics\n",
      "\n",
      "Invalid DataFrame shape: (10, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import json\n",
    "\n",
    "# Task: Metadata Management for Data Quality\n",
    "# Description: This script demonstrates how to store and use metadata to manage\n",
    "#              data quality in a pipeline using Python and Pandas.\n",
    "\n",
    "# Step 1: Load metadata\n",
    "# Metadata can define expected data types, allowed ranges, or other validation rules.\n",
    "# For simplicity, we'll define it as a Python dictionary here, simulating loading from a file.\n",
    "metadata = {\n",
    "    \"schema\": {\n",
    "        \"product_id\": {\"type\": \"int\", \"nullable\": False},\n",
    "        \"product_name\": {\"type\": \"str\", \"nullable\": False},\n",
    "        \"price\": {\"type\": \"float\", \"nullable\": False, \"min_value\": 0.01, \"max_value\": 1000.00},\n",
    "        \"stock_quantity\": {\"type\": \"int\", \"nullable\": False, \"min_value\": 0},\n",
    "        \"category\": {\"type\": \"str\", \"nullable\": True, \"allowed_values\": [\"Electronics\", \"Books\", \"Clothing\", \"Home Goods\"]}\n",
    "    },\n",
    "    \"quality_checks\": {\n",
    "        \"price_range\": \"price >= min_value and price <= max_value\",\n",
    "        \"stock_positive\": \"stock_quantity >= min_value\",\n",
    "        \"category_valid\": \"category in allowed_values or category is None\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Step 1: Metadata Loaded.\")\n",
    "print(json.dumps(metadata, indent=2))\n",
    "\n",
    "# Step 2: Load data (simulated)\n",
    "# We'll create a dummy DataFrame with some data, including some that violates the metadata.\n",
    "csv_data = \"\"\"\n",
    "product_id,product_name,price,stock_quantity,category\n",
    "101,Laptop,1200.50,50,Electronics\n",
    "102,Novel,15.99,200,Books\n",
    "103,T-Shirt,25.00,150,Clothing\n",
    "104,Coffee Maker,99.99,30,Home Goods\n",
    "105,Invalid Price,-5.00,10,Electronics\n",
    "106,Zero Stock,50.00,0,Books\n",
    "107,Invalid Category,100.00,20,Gadgets\n",
    "108,Missing Stock,200.00,,Electronics\n",
    "109,Missing Price,,5,Clothing\n",
    "110,Valid Product,75.00,100,Electronics\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(io.StringIO(csv_data))\n",
    "    print(\"\\nStep 2: Data Loaded.\")\n",
    "    print(\"\\nOriginal DataFrame:\")\n",
    "    print(df)\n",
    "    print(f\"\\nOriginal DataFrame shape: {df.shape}\")\n",
    "\n",
    "    # Step 3: Use metadata to validate data quality\n",
    "    invalid_rows_indices = set()\n",
    "    validation_results = []\n",
    "\n",
    "    print(\"\\nStep 3: Validating Data Quality using Metadata...\")\n",
    "\n",
    "    # Validate based on schema (data types and nullability)\n",
    "    for col_name, col_meta in metadata[\"schema\"].items():\n",
    "        if col_name not in df.columns:\n",
    "            print(f\"Error: Column '{col_name}' defined in metadata but not found in data.\")\n",
    "            continue\n",
    "\n",
    "        # Validate data types\n",
    "        expected_type_str = col_meta[\"type\"]\n",
    "        if expected_type_str == \"int\":\n",
    "            expected_type = int\n",
    "        elif expected_type_str == \"float\":\n",
    "            expected_type = float\n",
    "        elif expected_type_str == \"str\":\n",
    "            expected_type = str\n",
    "        else:\n",
    "            print(f\"Warning: Unknown type '{expected_type_str}' for column '{col_name}'. Skipping type validation.\")\n",
    "            continue\n",
    "\n",
    "        # Convert column to object type first to handle mixed types gracefully before checking\n",
    "        # This helps in identifying actual type mismatches rather than coercion errors\n",
    "        df[col_name] = df[col_name].apply(lambda x: x if pd.isna(x) else x)\n",
    "\n",
    "        # Check for type mismatches (ignoring NaN for numerical types)\n",
    "        type_mismatch_mask = df[col_name].apply(lambda x: not isinstance(x, expected_type) if pd.notna(x) else False)\n",
    "        if type_mismatch_mask.any():\n",
    "            invalid_rows_indices.update(df[type_mismatch_mask].index.tolist())\n",
    "            validation_results.append(f\"Type mismatch in '{col_name}': {df[type_mismatch_mask][col_name].tolist()}\")\n",
    "\n",
    "        # Validate nullability\n",
    "        if not col_meta[\"nullable\"] and df[col_name].isnull().any():\n",
    "            null_mask = df[col_name].isnull()\n",
    "            invalid_rows_indices.update(df[null_mask].index.tolist())\n",
    "            validation_results.append(f\"Null values in non-nullable column '{col_name}'\")\n",
    "\n",
    "        # Validate range for numerical types\n",
    "        if expected_type_str in [\"int\", \"float\"]:\n",
    "            if \"min_value\" in col_meta and \"max_value\" in col_meta:\n",
    "                min_val = col_meta[\"min_value\"]\n",
    "                max_val = col_meta[\"max_value\"]\n",
    "                # Ensure column is numeric before range check, coerce errors to NaN\n",
    "                numeric_col = pd.to_numeric(df[col_name], errors='coerce')\n",
    "                range_violation_mask = ~numeric_col.between(min_val, max_val, inclusive='both') & pd.notna(numeric_col)\n",
    "                if range_violation_mask.any():\n",
    "                    invalid_rows_indices.update(df[range_violation_mask].index.tolist())\n",
    "                    validation_results.append(f\"Out of range values in '{col_name}': {df[range_violation_mask][col_name].tolist()}\")\n",
    "            elif \"min_value\" in col_meta: # Only min_value check\n",
    "                min_val = col_meta[\"min_value\"]\n",
    "                numeric_col = pd.to_numeric(df[col_name], errors='coerce')\n",
    "                min_violation_mask = (numeric_col < min_val) & pd.notna(numeric_col)\n",
    "                if min_violation_mask.any():\n",
    "                    invalid_rows_indices.update(df[min_violation_mask].index.tolist())\n",
    "                    validation_results.append(f\"Below min_value in '{col_name}': {df[min_violation_mask][col_name].tolist()}\")\n",
    "\n",
    "        # Validate allowed values for categorical types\n",
    "        if expected_type_str == \"str\" and \"allowed_values\" in col_meta:\n",
    "            allowed_values = col_meta[\"allowed_values\"]\n",
    "            # Check if category is not in allowed values and is not null (if nullable=True)\n",
    "            if col_meta[\"nullable\"]:\n",
    "                invalid_category_mask = ~df[col_name].isin(allowed_values) & pd.notna(df[col_name])\n",
    "            else:\n",
    "                invalid_category_mask = ~df[col_name].isin(allowed_values)\n",
    "\n",
    "            if invalid_category_mask.any():\n",
    "                invalid_rows_indices.update(df[invalid_category_mask].index.tolist())\n",
    "                validation_results.append(f\"Invalid category in '{col_name}': {df[invalid_category_mask][col_name].tolist()}\")\n",
    "\n",
    "\n",
    "    # Identify invalid rows based on collected indices\n",
    "    invalid_data_df = df.loc[list(invalid_rows_indices)].copy()\n",
    "    valid_data_df = df.drop(index=list(invalid_rows_indices)).copy()\n",
    "\n",
    "    print(\"\\nData Quality Validation Summary:\")\n",
    "    if not validation_results:\n",
    "        print(\"All data passed quality checks based on metadata.\")\n",
    "    else:\n",
    "        print(\"The following data quality issues were found:\")\n",
    "        for res in validation_results:\n",
    "            print(f\"- {res}\")\n",
    "\n",
    "    # Step 4: Show valid data\n",
    "    print(\"\\nStep 4: Valid Data (rows that passed all quality checks):\")\n",
    "    if not valid_data_df.empty:\n",
    "        print(valid_data_df)\n",
    "        print(f\"\\nValid DataFrame shape: {valid_data_df.shape}\")\n",
    "    else:\n",
    "        print(\"No valid data found after applying quality checks.\")\n",
    "\n",
    "    print(\"\\nInvalid Data (rows that failed at least one quality check):\")\n",
    "    if not invalid_data_df.empty:\n",
    "        print(invalid_data_df)\n",
    "        print(f\"\\nInvalid DataFrame shape: {invalid_data_df.shape}\")\n",
    "    else:\n",
    "        print(\"No invalid data found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during metadata-driven data quality validation: {e}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
